---
title: "Practica 4 - Atur"
author: "Juan Pablo Zaldivar && Enric Millan"
date: "2023-03-10"
output: html_document
---

# Atur

## Introducción

```{r, echo=FALSE, include=FALSE}
library(car)
library(zoo)
library(ggplot2)
library(forecast)
library(ggfortify)
library(TSstudio)
```

```{r}
ser <- ts(read.table("Atur.dat", header=F)/1000,start=1996,freq=12)
#ser <- ts(read.table("../Data/Atur.dat", header=F)/1000,start=1996,freq=12)
# autoplot(ser, main="", ylab="", xlab="Time", ts.colour = '#45B39D', ts.geom='ribbon', ts.fill='#73C6B6')
ts_plot(ser, slider=TRUE)
# plot(ser)

```

```{r}
lnser <- log(ser)
d12lnser = diff(lnser, 12)
d1d12lnser = diff(d12lnser)
```

...?

### Modelo 1

$$\mbox{ARIMA}(1,1,1)(0,1,1)_{12}$$

$$(1 - \phi_1 B)(1-B)(1-B^{12})X_t = (1 + \theta_1 B)(1 + \Theta_1 B^{12})Z_t$$

...

```{r}
m1 <- arima(d1d12lnser, order=c(1,0,1), seasonal=list(order=c(0,0,1), period=12))
m1
```

...

```{r}
cat("Is the mean significant?",
    abs(m1$coef[4]/sqrt(diag(m1$var.coef)[4])) > 2)
```

...

```{r}
m1 <- arima(lnser, order=c(1,1,1), seasonal=list(order=c(0,1,1), period=12))
m1
```

...

```{r}
cat("\nT-ratios:",round(m1$coef/sqrt(diag(m1$var.coef)),2))
```

...

### Modelo 2

SE TIENE QUE HACER LO MISMO PARA EL MODELO 2??????????????

$$\mbox{ARIMA}(8,1,0)(0,1,1)_{12}$$

$$(1 - \phi_1 B - \phi_2 B^2 - \phi_3 B^3 - \phi_4 B^4 - \phi_5 B^5 - \phi_6 B^6 - \phi_7 B^7 - \phi_8 B^8)(1-B)(1-B^{12})X_t = (1 + \Theta_1 B^{12})Z_t$$

...

```{r}
m2 <- arima(d1d12lnser, order=c(8,0,0), seasonal=list(order=c(0,0,1), period=12))
m2
```

...

```{r}
cat("Is the mean significant?",
    abs(m2$coef[10]/sqrt(diag(m2$var.coef)[10])) > 2)
```

...

```{r}
m2 <- arima(lnser, order=c(8,1,0), seasonal=list(order=c(0,1,1), period=12))
m2
```

...

```{r}
cat("\nT-ratios:",round(m2$coef/sqrt(diag(m2$var.coef)),2))
```


## 1. Variancia constante

**Feu el plot dels residus i el de l'arrel quadrada del valor aboluts dels residus amb ajust suau. Podem considerar que la variancia es constant?**

### Modelo 1

A modo de visualizar la variabilidad de los residuos del modelo 1, se dibujan los siguientes dos gráficos para visualizar como estan distribuidos. Es deseable que el $99,7%$ de los residuos se encuentren dentro de las bandas de probabilidad para poder considerar una variabilidad constante.

Se busca comentar la presencia de outliers en los residuos o incluso indicios de volatibilidad de la variancia.

```{r}
resi1 <- resid(m1)
plot(resi1); abline(h=0); abline(h=c(-3*sd(resi1),3*sd(resi1)),lty=3,col=4)
```

Se observan valores atípicos que sobresalen de las lineas de probabilidad. Estos son considerados como outliers y probablemente sean explicados por factores externos a la serie temporal. Dichos valores de residuos suman un total de aproximadamente 4 muestras, lo que corresponde a un $1,45%$ de las observaciones de la serie temporal.

En este mismo gráfico algunos intervalos se podrían interpretar como clusters de volatilidad, aunque no muy distinguibles a simple vista. Por lo que, de momento, no seria razonable admitir una varianza considerablemente constante, principal mente debido a el número elevado de valores atípicos de la serie.


```{r}
scatter.smooth(sqrt(abs(resi1)), lpars=list(col=2))
```

Gracias al ajuste local suave de la variabilidad de la serie en el gráfico de arriba, se observa que la linea de estimación no es del todo horizontal, sino que presenta una curvatura concava. Lo cual descalifica, junto a las demás razones explicadas, el modelo 1 para considerar variancia constante.

### Modelo 2

Es deseable no encontrar una frecuencia excesiva de residuos fuera de los intervalos de confianza, ya que esto contradiría la hipótesis de homocedasticidad de los residuos. De igual manera, se busca comentar la presencia de outliers en los residuos o incluso indicios de volatibilidad de la variancia.

```{r}
resi2 <- resid(m2)
plot(resi2); abline(h=0); abline(h=c(-3*sd(resi2),3*sd(resi2)),lty=3,col=4)
```

Para el gráfico de los residuos en el segundo modelo se observan un total de 3 valores atípicos, que corresponden al $1,09%$ de las muestras, por lo que, una vez más, esto podría ocasionar problemas para confirmar la hipótesis de homocedasticidad de la variancia.

```{r}
scatter.smooth(sqrt(abs(resi2)), lpars=list(col=2))
```

El segundo gráfico nos muestra una tendencia similar a la del primer modelo, pero aún más acentuada, presentando una curvatura mayor. Por lo que, si en el anterior modelo se ha descartado variancia cosntante, la decisión de descartarlo en este modelo es aun mas justificada.

## 2. Hipótesis de Normalidad

**Feu el plot de normalitat i l’histograma amb la corba normal superposada. Aplica el test de Shapiro-Wilks als residus. Podem considerar que els residus provenen d’una distribucio normal?**

### Modelo 1

En la gráfica de normalidad, los residuos de las observaciones intermedias parecen ajustarse fielmente con los cuantiles teóricos de bajo la distribución de la normalidad. Sin embargo, se observan un conjunto seguido de puntos en ambos extremos que se separan de las linea de ajuste, lo cual confirma el hecho de una posible volatilidad en los residuos. Indicando que el modelo 1 no es suficiente para explicar la serie.

```{r}
qqPlot(resi1, main="Normal Q-Q Plot", xlab="Theoretical Quantiles", ylab="Sample Quantiles", grid=FALSE)
qqline(resi1,col=2,lwd=2)
```

Por otro lado, no se observa una asimetría en los residuos, ya que no hay una curvatura notable a la hora de graficarlos. Lo que si es que se pueden identificar unos valores que posiblemente puedan ser considerandos como outliers, detalle ya mencionado previamente en el apartado anterior. Se identifican rápidamente al estar separados del resto de valores y adémas de estar en los extremos del ajuste.

```{r}
hist(resi1,breaks=20, freq=FALSE)
curve(dnorm(x, mean=mean(resi1), sd=sd(resi1)), col=2, add=T)
```

Con el centro del histrograma se podría admitir que el modelo 1 cumple la hipotesis de normalidad. En cambio, a los extremos de las curvas de la distribución hay barras que sobresalen con una mayor frecuencia que la que se habría de esperar bajo la hipotesis de normalidad. Dichas *heavy tails* son, una vez más, una confirmación de la volatidlidad que presenta la serie.


```{r}
shapiro.test(resi1)
```

Después de realizar el test de Shapiro-Wilk, se rechaza la hipotesis nula y no se confirma que los residuos del modelo 1 siguan una distribución normal. Todo esto debido, además de las justificaciones previas, a que el `pvalor` del test estadistico es inferior al grado de significación $0.05$.

### Modelo 2

En el caso del modelo 2, nuevamente la región central se ajusta correctamente a la hipotesis de normalidad. En cambio, los extremos difieren considerablemente ya que incluso se alejan del intervalo de confianza.

Si bien se podría considerar que en el extremo inferior solo hay presencia de un número reducido de outliers, para el extremos superior no se puede validar la misma asunción. Por lo que se tendría que considerar una presencia de *heavy tails*, por lo menos, en el extremo superior, debido a esta separación continua de los residuos.

```{r}
qqPlot(resi2, main="Normal Q-Q Plot", xlab="Theoretical Quantiles", ylab="Sample Quantiles", grid=FALSE)
qqline(resi2,col=2,lwd=2)
```

El histograma confirma que los residuos distribuidos en el último cuartil no encajan con la hipotesis de normalidad al tener una frecuencia elevada que sobrepasa la curvatura de la distribución normal.

```{r}
hist(resi2,breaks=20, freq=FALSE)
curve(dnorm(x, mean=mean(resi2), sd=sd(resi2)), col=2, add=T)
```

Para terminar de confirmar que no se satisface la normalidad de los residuos, se efectua el test Shapiro-Wilk, obteniendo un `pvalor` muy por debajo del nivel de significación establecido.

```{r}
shapiro.test(resi2)
```

De modo que la conclusión final es que el modelo 2 no cumple con la condición de normalidad de residuos.

## 3. Independencia de residuos

**Feu l’ACF i el PACF dels residus i la representacio dels p-valors pel test de Ljung-Box. Podem considerar que els residus son independents?**

### Modelo 1

Para el primer modelo propuesto, se observa que los retrasos estacionales encajan a la perfección en las bandas de confianza, por tanto se confirma que la componente estacional del modelo 1 explica adecuadamente el patrón estacional de la serie temporal.

En cambio, para el caso regular, en ambos gráficos sobresale notablemente el sexto retraso. Esto nos indica que el modelo 1 podría no estar explicando bien la serie temporal y por tanto no estar cumpliendo la independencia de los residuos. 

Aunque su significación de estos retrasos es clara, se confirmará con el test estadistico de Ljung-Box para ver si puede ser por fruto del azar, aunque muy problablemnete no se pueda justificar de esa manera al estar relativamente cerca del origen.

```{r}
par(mfrow=c(1, 2)) # plot two graphics
acf(resi1, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(2, rep(1,11)))
pacf(resi1, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(rep(1, 11),2))
```

Notese que el sexto retraso (y algunos contiguos) tienen un `pvalor` inferior a $0.05$ en el test de Ljung-Box, lo que indica que no se puede considerar que sea fruto del azar. Por tanto, no se puede confirmar la hipotesis de independencia de los residuos. La cual es la condición más importante al tratarse de una serie temporal y que implica que este modelo no representaría la serie de forma correcta.

```{r}
tsdiag(m1,gof.lag=72)
```

Dicha conclusión de que el modelo 1 actual no es suficiente, convendría reformular la identificación del modelo 1 para poder conseguir, dentro de lo posible, un comportamiento de los residuos similar al de *White Noise*.

### Modelo 2

Analizando ambos gráficos, se observa rápidamente que ningun retraso (ni estacional ni regular) sobrepasa las bandas de confianza de manera significativa, indicando que los residuos de la parte estacional como la regular tienen una estructura de correlación no significativa. Lo cual conlleva a que los residuos se ajusten convenientemente al comportamiento de un *White Noise*.

El único retraso que llega a rozar, incluso exceder el límite del intervalo de confianza es el número 30. Sin embargo, debido a lo lejano que está del origen y lo poco que llega a sobrepasar dicho límite, se considerará que forma parte del $5%$ de azar. El test de Ljung-Box permitirá confirmar dicha desición.

```{r}
par(mfrow=c(1, 2)) # plot two graphics
acf(resi2, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(2, rep(1,11)))
pacf(resi2, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(rep(1, 11),2))
```

Observando el test estadistico incremental de Ljung-Box, se confirma que el único retraso "significativo" detectado anteriormente, puede considerarse fruto del azar, debido a que su `pvalor` excede por mucho el grado de significación determinado. De manera que no se rechaza la hipotesis nula.

```{r}
tsdiag(m2,gof.lag=72)
```

Como todo el conjunto de retrasos confirman ser no significativos y ajustarse a la condición de independencia, se puede validar que el modelo 2 cumple con la independencia de residuos.

## 4. Modelo causal/invertible

**Pels polinomis caracteristics de la part AR i MA, calculeu el modul de les seves arrels. El model estimat, es causal? es invertible?**

### Modelo 1

Al ser un modelo **ARMA**, se pueden comprobar si el modelo propuesto cumple con ambas propiedades. Es decir, que los pesos de $\psi(B)$ y $\pi(B)$ tienen convergencia.

Se comenzará comprobando si el modelo 1 es casual/estacionario, para ello se han de comprobar que el módulo de todas las raices del polinómio característico del componente autoregresivo $\phi_p(B)$ sean mayor que la unidad.

```{r}
Mod(polyroot(c(1,-m1$model$phi)))
```

Como solo hay una única raíz y es superior a 1, el modelo 1 puede definirse como causal.

Para comprobar si el modelo 1 es invertible, se mirarán las raices ahora de un polinomio de grado $13$, resultado conjunto de la parte regular y estacional del modelo.

```{r}
Mod(polyroot(c(1,m1$model$theta)))
```

Como todas tienen modulo mayor que la unidad, también se puede caracterizar el modelo como invertible. 

```{r}
plot(m1)
```

Se comprueba visualmente que, en este caso, la inversa de las raices de los dos polinomios caen dentro del circulo unitario, por lo tanto, el modelo 1 es tanto causal como invertible.

### Modelo 2

Se comenzará comprobando si el modelo 2 es casual/estacionario, para ello se han de comprobar que el módulo de todas las raices del polinómio característico del componente autoregresivo $\phi_p(B)$ sean mayor que la unidad.

```{r}
Mod(polyroot(c(1,-m2$model$phi)))
```

Al tener todas las raices modulo mayor que 1, el modelo 2 puede definirse como causal.

Para comprobar si el modelo 2 es invertible, se mirarán las raices ahora de un polinomio de grado $12$, al solo contar con la componente estacional.

```{r}
Mod(polyroot(c(1,m2$model$theta)))
```

Como todas tienen modulo mayor que la unidad, también se puede caracterizar el modelo como invertible. 

```{r}
plot(m2)
```

Se comprueba visualmente que, en este caso, la inversa de las raices de los dos polinomios caen dentro del circulo unitario, por lo tanto, el modelo 2 es tanto causal como invertible.

## 5. Medidas de adecuación

**Calculeu les mesures d’adequació a les dades (AIC i BIC)**

### Modelo 1

AIC i BIC del modelo 1:

```{r}
AIC(m1); BIC(m1)
```

### Modelo 2

AIC i BIC del modelo 2:

```{r}
AIC(m2); BIC(m2)
```

## 6. Estabilidad del modelo

**Ajusteu el model amb totes les dades i amb les dades sense les 12 darreres observacions. Podem considerar estable el model?**

Primero declaramos la serie sin sus últimas doce muestras para poder comprobar si los modelos propuestos son estables.
```{r}
ultimo=c(2017,12); serie_2=window(ser, end=ultimo)
```

### Modelo 1

```{r}
m1_2 <- arima(log(serie_2), order=c(1,1,1), seasonal=list(order=c(0,1,1), period=12))
m1_2
m1
```
Como se puede observar los coeficientes de el modelo completo y el modelo carente de las últimas 12 observaciones son prácticamente iguales: mismo signo y magnitud muyu similar.

Para acabar de confirmar que el modelo 1 es un  modelo estable veamos si ambos conjuntos de coeficiente también tienen una signifiación muy parecida:

```{r}
cat("\nT-ratios:",round(m1$coef/sqrt(diag(m1$var.coef)),2))
cat("\nT-ratios:",round(m1_2$coef/sqrt(diag(m1$var.coef)),2))
```
Las significaciones son casi idénticas por lo que podemos afirmar que el Modelo 1 es un modelo estable.

### Modelo 2

```{r}
m2_2 <- arima(log(serie_2), order=c(8,1,0), seasonal=list(order=c(0,1,1), period=12))
m2_2
m2
```
Una vez más tanto el modelo completo como el modelo de la serie sin sus últimas doce observaciones constan de coeficientes con el mismo signo y magnitudes muy similares.

Comprobemos su significación para corroborar que el Modelo 2 también es un modelo estable:

```{r}
cat("\nT-ratios:",round(m2$coef/sqrt(diag(m1$var.coef)),2))
cat("\nT-ratios:",round(m2_2$coef/sqrt(diag(m1$var.coef)),2))
```
Como se observa, los t-ratios de los coeficientes son casi idénticos por lo que también podemos decir que el Modelo 2 es un modelo estable.

## 7. Predicciones puntuales

**Pel model ajustat sense les 12 darreres observacions, obtingueu les prediccions puntuals i el corresponent interval de confianca al 95% per a l’ultim any. Feu la representacio de la serie original (darrers 5 anys) amb les prediccions i intervals superposats.**

### Modelo 1

```{r}

```

### Modelo 2

```{r}

```

## 8. Medidas de capacidad de predicción

**Calculeu les mesures de capacitat de previsio (RMSPE i MAPE) a partir de les prediccions puntuals anteriors. Aixo dona una idea de l’exactitud de les prediccions.**

### Modelo 1

```{r}

```

### Modelo 2

```{r}

```

## 9. Intervalos de confianza

**Calculeu la mitjana de les amplades dels intervals de confinaca de prediccio. Aixo es una mesura de la precisio de les prediccions.**

### Modelo 1

```{r}

```

### Modelo 2

```{r}

```

## 10. Selección del modelo

**Amb tota la informacio anterior, quin dels dos models proposats seleccioneu com a millor? Pel model escollit ajustat amb totes les dades, calculeu les previsions amb intervals de confianca pel proper any**

```{r}

```










.