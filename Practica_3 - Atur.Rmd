---
title: "Practica 3 - Atur && AirPrat, Grupo 11"
author: "Juan Pablo Zaldivar && Enric Millán Iglesias"
date: "2023-03-04"
output:
  pdf_document: default
  html_document: default
---

# ATUR

## 1.

**Carregueu el fitxer que conte la serie. Definiu les dades llegides com a objecte de tipus ts (time series) indicant l'origen i la frequencia de la serie.**

```{r}
ser <- ts(read.table("../Data/Atur.dat", header=F)/1000,start=1996,freq=12)
```

## 2.

**Feu la representacio grafica de la serie temporal. Descriviu els aspectes mes rellevants que s'observen a simple vista.**

```{r}
plot(ser,main="Paro registrado en España (miles de personas)", ylab="Personas")
abline(v=1990:2019,col=4,lty=3)
plot(decompose(ser))
```

Se observa que la serie presenta un claro incremento de personas en el paro a partir del año 2008, muy posiblemente por la crisis financiera que sufrió en España (2008-2014). De la cual, después en el tiempo se nota el intento de su disminución como resultado de las medidas de apoyo del gobierno.

Notese un patrón estacional claro en lo que respecta a un incremento del paro en la temporada de invierno y su respectivo descenso en el periodo del verano.

## 3.

**Apliqueu les transformacions adients per convertir la serie en estacionaria.**

### 3.1 Variancia constante

A modo de comprobar una variabilidad en la serie se realizan gráfico de las medias y variancias de grupos de observaciones así como también un gráfico de los boxplot por periodos.

```{r}
# Calculate the mean and variance of consecutive groups of 8-12 observations.
m <- apply(matrix(ser, nrow=12), 2, mean)
v <- apply(matrix(ser, nrow=12), 2, var)
# Plot the variance against the mean of each group.
plot(v~m, ylab="Variance", xlab="Mean")
```

Se detectan grupos con una variancia ligeramente superior en la parte "alta" de la serie en comparación con la parte inferior. Igualmente vemos un grupo muy por encima del resto de grupos, que podría deberse a una observación atípica.

```{r}
# Measurement of dispersion, ignoring outilers.
boxplot(ser~floor(time(ser)))
```

A partir del segundo gráfico se puede reafirmar una variabilidad ligeramente superior en los últimos años. Por lo tanto, aunque pudiese parecer que no es neceario aplicar la transformación `log()`, hemos visto que los modelos propuestos en apartados posteriores obtienen mejores resultados si aplicamos esta transformación.

```{r}
lnser <- log(ser)
plot(lnser, main="Log paro registrado en España (miles de personas)")
abline(v=1990:2020, lty=3, col=4)
```

```{r}
boxplot(lnser~floor(time(lnser)))
```

Aunque leve, se nota una mejora respecto a la serie carente de transformación.

### 3.2 Patrón estacional

Para buscar un posible patrón estacional de orden 12, se grafican las subseries de la serie original por meses para observar la distribución de cada una de las medias.

```{r}
monthplot(lnser)
```

```{r}
ts.plot(matrix(lnser, nrow=12), col=1:8)
```

Vease que en los meses de Abril a Septiembre hay una media ligeramente por debajo del resto del año, con lo se puede deducir que hay un patrón que se repite al no tener las medias alineadas horizontalmente.

Es posible suponer que esto se debe al incremento de la demanda para el trabajo al tratarse de la temporada de verano, es decir, de vacaciones.

Se requiere de una diferenciación estacional para eliminar el patrón de la serie.

```{r}
d12lnser = diff(lnser, 12)
plot(d12lnser,main="Serie después de la diferenciación estacional")
abline(v=1990:2019,col=4,lty=3)
```

Después de aplicar este filtro lineal las medias de cada subserie se alinean horizontalmente.

```{r}
monthplot(d12lnser)
```

```{r}
ts.plot(matrix(d12lnser, nrow=12), col=1:8)
```

En este segundo gráfico también se aprecia que ha desaparecido cualquier tipo de patrón estacional que la serie pudiese tener.

### 3.3 Media constante

Se aplica una diferenciación regular hasta que la media de la serie se pueda considerar constante, ya que como se observa en el gráfico de la serie transformada d12lnser, la media no es constante con el tiempo.

```{r}
d1d12lnser = diff(d12lnser)
plot(d1d12lnser,main="Serie después de la diferenciación regular")
abline(v=1990:2019,col=4,lty=3)
abline(h=mean(d1d12lnser), col=2) # mean of the series.
```

Vemos que la serie ya consta de una media bastante constante y definida pero hay que revisar que no haya incrementado la variancia:

```{r}
var(d12lnser)
var(d1d12lnser)
```

Repetir hasta que se detecte un incremento de la variancia de la serie.

```{r}
d1d1d12lnser = diff(d1d12lnser)
plot(d1d1d12lnser,main="Serie después de la diferenciación regular")
abline(v=1990:2019,col=4,lty=3)
abline(h=mean(d1d1d12lnser), col=2)
```

Con esta segunda diferenciación la media se hace más constante pero como vemos a continuación la variancia aumenta así que descartaremos esta segunda diferenciación regular.

```{r}
var(d1d12lnser)
var(d1d1d12lnser)
```

### 3.4 Serie estacionaria resultante

```{r}
plot(d1d12lnser,main="Serie Estacionaria")
abline(v=1990:2019,col=4,lty=3)
abline(h=mean(d1d12lnser), col=2) # mean of the series.
```

Tras aplicar las transformaciones, la serie estacionaria $W_t$ queda de la siguiente forma:

$$W_t = (1-B)(1-B^{12})\log{X_t}$$

Con $d = 1$ y $D = 1$.

## 4.

**Per a la serie transformada, representeu l'ACF i la PACF.**

### 4.1 ACF Y PACF muestral

```{r}
par(mfrow=c(1, 2)) # plot two graphics
acf(d1d12lnser, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(2, rep(1, 11)))
pacf(d1d12lnser, ylim=c(-1, 1), lag.max=60, lwd=2, col=c(rep(1, 11), 2))
```

Ambos gráficos tienen, aunque distinto, un patrón de decreciemiento, por lo tanto se pueden extraer tanto posibles modelos *AR(p)*, *AR(P)* como *MA(q)*, *MA(Q)*.

Para determinar los valores de `p, P` y `q, Q` se necesita contar el número de retrasos hasta la última barra significativamente diferente de $0$. $\rho(h) \neq 0$. Con lo que la última barra debe encontrarse fuera de las bandas del intervalo de confianza para poder rechazar la hipotesis nula de significación de $\rho(h)$.

$$H_0: \rho(h) = 0 \\ H_1: \rho(h) \neq 0$$

Considerando estas opciones se ve que los modelos regulares *AR(p)* y *MA(q)* resultantes constan de demasiados parámetros, puesto que, en el caso del **PACF** y **ACF** hay varios retrasos significativos al estar lejos de las bandas de confianza, además de estar cerca del origen y por lo tanto no se pueden siquiera considerar como retrasos satélites u ocasionados por el azar.

Mirando los retrasos correspondientes a la parte regular del gráfico **PACF** se tiene que contar hasta la sexta barra pues esta muestra una notable significación estando cerca del origen y lejos del retraso esatcional para descartarlo como posible satélite en consecuencia. Lo que propondría un modelo *AR(6)*.

Del mismo modo, en el gráfico **ACF** se ve claramente una subsecuencia de los retrasos significativa contenida hasta las seis primeras barras, sin contar la autocorrelación 0. De tal modo se requeriría un modelo *MA(6)* de seis parámetros. Se ha de tener en cuenta, que dicho modelo tiene una alta complejidad, al igual que el modelo *AR* propuesto con anterioridad.

Por lo que se propondrá incialmente un modelo *ARMA(1,1)*, para reducir la complejidad del modelo, lo que asegura en cierta medida una estabilidad en las predicciones que se vayan a realizar. Esto al tener un menor número de parámetros en comparación de unos posibles mdoelos *AR(6)* o *MA(6)*. También es correcto analizar las posibilidades con modelos *ARMA(2,1)* y *ARMA(1,2)*, pero por minimizar la complejidad optaremos por el ya mencionado *ARMA(1,1)*.

Respecto a la parte estacional, se puede tener en cuenta tanto un *AR(2)* como un *MA(2)*. En el caso del modelo *AR(2)* porque los retrasoso estacionales el **PACF** presentan un decrecimiento y solo los dos primeros son significativos. Para el caso del modelo de la media móvil *MA(2)* se debe nuevamente a las dos barras estacionales que sobresalen del intervalo de confianza. No se tiene en cuenta la primera de todas al ser la autocorrelación para $k=0$.

## 5.

**En base a l'ACF i PACF mostral, proposeu almenys dos models per a cada serie, justificant la proposta.**

Con el análisis anterior, los parámteros posibles quedan de la siguiente forma$P = 2,\ Q = 2,\ p = 1 \ \mbox{y}\ q = 1$. Lo que resulta en $2$ modelos posibles:

$$\mbox{ARIMA}(1,1,1)(2,1,0)_{12} \\ \mbox{ARIMA}(1,1,1)(0,1,2)_{12}$$

### 5.1 Modelo 1 propuesto

Considerese el modelo $\mbox{ARIMA}(1,1,1)(2,1,0)_{12}$ como el primer modelo propuesto.

$$(1-\phi_1 B)(1 - \Phi_1 B^{12} - \Phi_2 B^{24})(1-B^{12})(1-B)\log{(X_t - \mu_1)} = (1+ \theta_1 B)Z_t$$

### 5.2 Modelo 2 propuesto

Considerese el modelo $\mbox{ARIMA}(1,1,1)(0,1,2)_{12}$ como el segundo modelo propuesto.

$$(1-\phi_1 B)(1-B^{12})(1-B)\log{(X_t - \mu_2)} = (1+ \theta_1 B)(1 + \Theta_1 B^{12} + \Theta_2 B^{24})Z_t$$

## 6.

**Feu l'estimacio dels models proposats i verifiqueu la significacio dels coeficients i que els residus tenen un ACF compatible amb un soroll blanc. Si hi ha algun coeficient no significatiu, elimineu-lo del model.**

### 6.1 Estimación modelo 1

Como se ha obtenido ya una serie $W_t$ estacionaria, tiene un solo valor de para la media de la serie $\hat{\mu_1}$, con lo que se procede a estimarla.

```{r}
mod1 <- arima(d1d12lnser, order=c(1,0,1), 
              seasonal=list(order=c(2,0,0), period=12))
mod1
```

Se comprueba la significación de $\hat{\mu_1}$ mediante su $t$-ratio para determinar si es significante para el modelo, es decir, si se acepta la hipotesis nula de que la media es igual a 0.

$$H_0: \hat{\mu_1} = 0 \\ H_1: \hat{\mu_1} \neq 0$$ donde el $t-$ratio viene dado por

$$t = \frac{\hat{\mu_1} - 0}{S_{W_t}} \sim N(0,1)$$

asintoticamente normal al tratarse de un estimador calculado a partir del estimador de máxima verosimilitud.

```{r}
cat("Is the mean significant?",
    abs(mod1$coef[5]/sqrt(diag(mod1$var.coef)[5])) > 2)
```

Al no tener significación la media de la serie $\hat{\mu_1}$, se puede aplicar la función `ARIMA` al logaritmo de la serie orignal aplicandole las diferenciaciones como parámetros a la función, de esta manera se evitan deshacer las transformaciones después y se puede predecir directamente sobre el logaritmo de la serie.

```{r}
mod1 <- arima(lnser, order=c(1,1,1), seasonal=list(order=c(2,1,0), period=12))
mod1
```

Verificamos que la decisión de retirar la media del modelo ha sido la adecuada en terminos del AIC del nuevo ajuste. Además como $\hat{\mu_1}$ no es significativa, se ve que los valores de los estimadores del modelo no han variado en gran escala, al igual que sus desviaciones estandar.

#### 6.1.1 Signifiación de los parámetros modelo 1

```{r}
cat("\nT-ratios:",round(mod1$coef/sqrt(diag(mod1$var.coef)),2))
```

Se observa que todos los parámetros de la parte estacional como regular son significativos al tener un $t-$ratio fuera del intervalo $[2,-2]$ para rechazar la hipótesis nula.

#### 6.1.2 ACF del residuo modelo 1

```{r}
par(mfrow=c(1, 2)) # plot two graphics
acf(resid(mod1), ylim=c(-1, 1), lag.max=60, lwd=2, col=c(2, rep(1, 11)))
pacf(resid(mod1), ylim=c(-1, 1), lag.max=60, lwd=2, col=c(rep(1, 11), 2))
```

Se observa que los retrasos que llegan a sobresalir de los intervalos de confianza, representan aproximadamente el 5% de azar por lo que se puede afirmar que es un **ACF** compatible con una **ACF** de *White Noise*.

De igual manera se observa que los que sobresalen lo hacen considerablemente lejos del origen, lo que indica que no hacen falta más parámetros al modelo. Se detectan una componente del retraso en cada uno de los gráficos, que aunque a distancia del origen, si se desea tener un modelo cuyo **ACF**y**PACF**se ajusten más al de un *White Noise,* se deberia analizar los dos posibles modelos siguientes; ARIMA(2,1,1) o ARIMA(1,1,2).

Pero se ha optado en este caso, se ha aceptado el modelo propuesto ya que también se busca una reducción de complejidad.

Los retrasos estacionales no son significativos, por lo que el modelo explica adecuadamente el componente estacional.

### 6.2 Estimación modelo 2

Nuevamente se comprubeba la significación de la media $\hat{\mu_2}$, esta vez para el segundo modelo propuesto.

```{r}
mod2 <- arima(d1d12lnser, order=c(1,0,1),
              seasonal=list(order=c(0,0,2), period=12))
mod2
```

Se comprueba la significación de $\hat{\mu_2}$ mediante su $t$-ratio para determinar si es significante para el modelo, es decir, si se acepta la hipotesis nula de que la media es igual a 0.

$$H_0: \hat{\mu_2} = 0 \\ H_1: \hat{\mu_2} \neq 0$$

donde el $t$-ratio viene dado por

$$t = \frac{\hat{\mu_1} - 0}{S_{W_t}} \sim N(0,1)$$

asintoticamente normal al tratarse de un estimador calculado a partir del estimador de máxima verosimilitud.

```{r}
cat("Is the mean significant?", abs(mod2$coef[5]/sqrt(diag(mod2$var.coef)[5])) > 2)
```

Al no tener significación la media de la serie $\hat{\mu_2}$, se puede aplicar la función `ARIMA` al logaritmo de la serie orignal aplicandole las diferenciaciones como parámetros a la función, de esta manera se evitan deshacer las transformaciones después y se puede predecir directamente sobre el logaritmo de la serie.

```{r}
mod2 <- arima(lnser, order=c(1,1,1), seasonal=list(order=c(0,1,2), period=12))
mod2
```

Verificamos que la decisión de retirar la media del modelo ha sido la adecuada en terminos del AIC del nuevo ajuste. Una vez más, los valores de los coeficientes apenas han variado ya que la media, como se ha comprobado, no era significativa.

#### 6.2.1 Signifiación de los parámetros modelo 2

```{r}
cat("\nT-ratios:",round(mod2$coef/sqrt(diag(mod2$var.coef)),2))
```

Para el segundo modelo propuesto, los parámetros de la parte regular son significativos al tener un $t$-ratio fuera del intervalo para no rechazar la hipótesis nula.

La parte estacional sin embargo, contiene un parámetro $\hat{\Theta_2}$ no significativo y lejos del límite del intervalo de confianza, por lo que ajustaremos un modelo eliminandolo y se compararán ambos modelos en terminos de su AIC.

```{r}
mod2b <- arima(lnser, order=c(1,1,1),seasonal=list(order=c(0,1,2), 
                                    period=12), fixed=c(NA, NA, NA, 0))
mod2b
```

Como el AIC ha disminuido, confirmamos que el parámetro no es significativo para el modelo ajustado y se ha de actualizar el modelo.

Así que el modelo resultante es un: $$\mbox{ARIMA}(1,1,1)(0,1,1)_{12}$$

```{r}
mod2b <- arima(lnser, order=c(1,1,1),seasonal=list(order=c(0,1,1), 
                                    period=12))
mod2b
```

```{r}
cat("\nT-ratios:",round(mod2$coef/sqrt(diag(mod2$var.coef)),2))
```

Se verifica que la significación del resto de parámetros se mantiene válida.

#### 6.2.2 ACF del residuo modelo 2

```{r}
par(mfrow=c(1, 2)) # plot two graphics
acf(resid(mod2b), ylim=c(-1, 1), lag.max=60, lwd=2, col=c(2, rep(1, 11)))
pacf(resid(mod2b), ylim=c(-1, 1), lag.max=60, lwd=2, col=c(rep(1, 11), 2))
```

El segundo modelo presenta una independencia entre los retrasos casi idéntica al primer modelo propuesto. Por lo tanto es lógico afirmar que presenta un **ACF** similar al **ACF** de un *White Noise*.

Los retrasos estacionales no son significativos, por lo que el modelo explica adecuadamente el componente estacional.

De igual manera se observa que no aparecen retardos cerca del origen, lo que indica que no hacen falta más parámetros al modelo. Tal y como se sucede en el primer modelo, se detectan una componente del retraso en cada uno de los gráficos, que aunque a distancia del origen, si se desea tener un modelo cuyo **ACF**y**PACF**se ajusten más al de un *White Noise,* se deberia analizar los dos posibles modelos siguientes; ARIMA(2,1,1) o ARIMA(1,1,2).

Pero se ha optado en este caso, se ha aceptado el modelo propuesto ya que también se busca una reducción de complejidad.

# 7.

**Indiqueu quin model proposarıeu, fent servir el criteri de l'AIC.**

```{r}
mod1$aic
mod2b$aic
```

En base al criterio del AIC, se escogería el segundo modelo quitando el parámetro $\Theta_2$ de la parte *MA* del modelo: $\mbox{ARIMA}(1,1,1)(0,1,1)_{12}$.

$$(1-\phi_1 B)(1-B^{12})(1-B)\log{(X_t - \mu_2)} = (1+ \theta_1 B)(1 + \Theta_1 B^{12})Z_t$$

$$(1-0.9374 B)(1-B^{12})(1-B)\log{(X_t - \mu_2)} = (1 - 0.6526 B)(1 - 0.5953 B^{12})Z_t$$

```{r}
mod2b
```
