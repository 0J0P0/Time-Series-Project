---
title: "Project"
author: "Juan Pablo Zaldivar && Enric Millan"
date: "2023-03-14"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo=FALSE) 
```

```{r}
library(car)
library(plotly)
library(webshot)
library(qqplotr)
library(forecast)
library(TSstudio)
```

# Titulo

...

# Indice

...

# Introducción

## Descripción Serie Temporal


```{r}
ser <- ts(read.table("Data/export.dat")/1000,start=1999,freq=12)
```

```{r}
f1 = plot_ly(x=~time(ser), y=~ser,
        type = "scatter",
        fill="tozeroy",
        mode="lines",
        line = list(color = "#2a788e"),
        fillcolor="rgba(42, 120, 142, 0.5)"
        ) %>% 
  layout(title='<b> Total exportations in Spain <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')
         )

f1;
```


```{r}
ds <- decompose(ser)

p1 <- plot_ly() %>% add_trace(x = time(ds$x), y = ds$x,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(34, 168, 132)"),
                              fillcolor="rgba(34, 168, 132, 0.5)",
                              name = "Original Time Series")
p2 <- plot_ly() %>% add_trace(x = time(ds$trend), y = ds$trend,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(42, 120, 142)"),
                              fillcolor="rgba(42, 120, 142, 0.5)",
                              name = "Trend")
p3 <- plot_ly() %>% add_trace(x = time(ds$seasonal), y = ds$seasonal,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(65, 68, 135)"),
                              fillcolor="rgba(65, 68, 135, 0.5)",
                              name = "Seasonal")
p4 <- plot_ly() %>% add_trace(x = time(ds$random), y = ds$random,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(68, 1, 84)"),
                              fillcolor="rgba(68, 1, 84, 0.5)",
                              name = "Random")

f2 = subplot(p1, p2, p3, p4, nrows=4) %>%
  layout(title='<b> Time Series Decomposition <b>')
f2;
```


## Motivación

## Descripción sintética

# Resultados e interpretación

...

## Identificación

...

### Transformación de la serie

...

#### Varianza constante

```{r}
m <- apply(matrix(ser, nrow=12), 2, mean)
v <- apply(matrix(ser, nrow=12), 2, var)

f3 = plot_ly(x=~m, y=~v,
        marker = list(size = 7,
                      color = '#2a788e',
                      line = list(color = '#414487',width = 1))
        ) %>%
  layout(title='<b> Varience~Mean <b>',
         xaxis=list(title='Mean'),
         yaxis=list(title='Variance'))
f3;
```


```{r}
f4 = plot_ly(x=~floor(time(ser)), y=~ser, type='box',
        boxpoints = 'suspectedoutliers',
        fillcolor="#2a788e",
        line=list(color="#414487")
        ) %>%
  layout(title='<b> Box Plot for periods <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='Time Series'))
f4
```

$$\frac{X_t^{\lambda}-1}{\lambda}, \ \ \lambda \in [-1,2], \ \lambda \neq 0$$

```{r}
lambda = BoxCox.lambda(ser, method = c("guerrero", "loglik"), lower = -1, upper = 2)
bcser = (ser^lambda-1)/lambda
```

```{r}
m <- apply(matrix(bcser, nrow=12), 2, mean)
v <- apply(matrix(bcser, nrow=12), 2, var)

f5 = plot_ly(x=~m, y=~v,
        marker = list(size = 7,
                      color = '#2a788e',
                      line = list(color = '#414487',width = 1))
        ) %>%
  layout(title='<b> Varience~Mean <b>',
         xaxis=list(title='Mean'),
         yaxis=list(title='Variance'))
f5
```

```{r}
f6 = plot_ly(x=~floor(time(bcser)), y=~bcser, type='box',
        boxpoints = 'suspectedoutliers',
        fillcolor="#2a788e",
        line=list(color="#414487")
        ) %>%
  layout(title='<b> Box Plot for periods <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='Time Series'))
f6
```

```{r}
f7 = plot_ly(x=~time(bcser), y=~bcser,
        type = "scatter",
        fill="tozeroy",
        mode="lines",
        line = list(color = "#2a788e"),
        fillcolor="rgba(42, 120, 142, 0.5)"
        ) %>% 
  layout(title='<b> Time series after Box-Cox transformation <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')
         )
f7
```


#### Patrón estacional


```{r}
f8 = ts_seasonal(bcser, type="all", title=" <b> Seasonality plot for Time Series <b>")

monthplot(bcser)

f8
```


$$(1-B^{12})X_t$$

```{r}
d12bcser = diff(bcser,12)
f9 = plot_ly() %>%
  add_trace(x=~time(d12bcser), y=~d12bcser,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d12bcser), y=~mean(d12bcser),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Time Series after seasonal differentation <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
f9
```

```{r}
monthplot(d12bcser)
```

```{r}
f10 = ts_seasonal(d12bcser, type="all", title=" <b> Seasonality plot for Time Series <b>")
f10
```


#### Media constante


```{r}
var(d12bcser)
var(diff(d12bcser))
var(diff(diff(d12bcser)))
```


```{r}
d1d12bcser = diff(d12bcser)
```

### Serie estacionaria

$$W_t = (1-B)(1-B^{12})\frac{X_t^\lambda-1}{\lambda} \ \ , \ \lambda≃0.395$$

```{r}
f11 = plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~d1d12bcser,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d12bcser), y=~mean(d12bcser),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Stationary Time Series <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
f11
```

### Modelos propuestos

Para poder proponer modelos deben analizarse los gráficos del ACF y el PACF de la serie tras haberle aplicado las transformaciones.

```{r}
f12 = ts_cor(d1d12bcser, lag.max = 72)
f12
```

Si bien es cierto que se observa cierta tendencia logarítmica en los retrasos del PACF, se considera que es el más adecuado para considerar los retrasos finitos inicialmente. Siendo el gráfico del ACF el que contiene infinitos retrasos no nulos.

Para determinar los valores de `p, P` y `q, Q` de los modelos ARMA se necesita contar el número de retrasos hasta la última barra significativamente diferente de 0. $\rho(h) \neq 0$. Con lo que la última barra que se considere debe encontrarse fuera de las bandas del intervalo de confianza para poder rechazar la hipótesis nula de no significación de $\rho(h)$.

$$H_0: \rho(h) = 0 \\ H_1: \rho(h) \neq 0$$

Comenzando por la parte estacional, se podría considerar ajustar AR(1), AR(2) y AR(4). Pues esta claro que el primer retraso estacional es significativo, mientras que el segundo y el cuarto sobresalen ligeramente por el límite inferior del intervalo de confianza. La opción de escoger una parte autoregresiva con $p=1$ puede razonarse como correcta al aportar una baja complejidad al modelo, sin embargo no es un candidato deseable al poder estar dejando parte sin explicar, por lo que es favorable decantarse por un AR(4) ya que se tendría en cuenta un mayor número de relaciones entre las variables del pasado, y si resulta haber parámetros no significativos, estos se pueden eliminar del ajuste.

Aun sabiendo que los retrasos del ACF no presentan un decreciemiento evidente, se podría considerar una media móvil de parámetro $q=6$ MA(6). Aunque los retrasos intermedios no presentan significación clara, el sexto retraso esatcional si es significativo. Esta propuesta incorpora al modelo una mayor complejidad en comparación con la parte autoregresiva propuesta con antelación, con lo que nos decantaremos inicialmente por mantener una parte AR(4) o bien proponer un ARMA que explique esta parte estacional, pero no se desechará el MA(6) hasta haber ajustado algunos modelos.

La decisión de presentar un ARMA estacional se debe a que las posibildades propuestas contienen un número considerable de parámetros. Tras experimentar con los casos que no superasen el número de parámetros mínimo ya presente (4 del AR(4)), se ha llegado a la conclusión, basandose en el AIC de los modelos que se han ajustado, de que el ARMA(2,2) y el ARMA(2,1) son los más adecuados junto al AR(4) y el MA(6). Todas las opciones son versátiles ya que pueden explicar retrasos que con opciones más simples no se considerasen y además permiten ser reducidos en caso necesario si algún coeficiente no es significativo.

Para la parte regular resulta muy evidente que la mejor opción es un AR(2), debido a que son los únicos dos retrasos con obvia significación. El resto de barras muestran este decreciemiento ya mencionado y aunque algunas sobresalen, estan suficientemente lejos del origen como para considerarse como fruto del $5%$ de azar en las observaciones.

No obstante, considerando únicamente un número limitado de los primeros retrasos del ACF, una propuesta MA(4) sería suficiente, pese a que se obviarían los retrasos siguientes. Por lo que se tendría que suponer que los retrasos significativos lejos del origen actúan como satélites de los retrasos estacionales.

Por el elevado número de parámetros propuestos, se estudiará proponer un modelo ARMA para reducir la complejidad del modelo también en la componente regular. Para reconocer cual es el modelo ARMA regular más adecuado, se han estudiado distintas combinaciones teniendo como base ARMA(1,1), ARMA(1,2), ARMA(2,1) y ARMA(2,2). Finalmente, teniendo en cuenta el AIC en primer lugar y la significación de parámetros en segundo lugar, las mejores opciones para la parte regular son el AR(2) y el ARMA(2,1).

Como se ha explicado, se han ajustados una gran cantidad de modelos para encontrar estos candidatos y para confirmar los que se identificaban a primera vista analizando el ACF y el PACF de la serie. Los cuatro mejores modelos identificados (en función principalmente del AIC) han sido los siguientes:

$$\mbox{ARIMA}(2,1,0)(0,1,6)_{12}$$

```{r}
arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(0,0,6), period=12))
```

$$\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$$

```{r}
arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(4,0,0), period=12))
```

$$\mbox{ARIMA}(2,1,0)(2,1,2)_{12}$$

```{r}
arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(2,0,2), period=12))
```

$$\mbox{ARIMA}(2,1,1)(2,1,1)_{12}$$

```{r}
arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(2,0,1), period=12))
```

Todos estos modelos tienen un AIC muy similar, por lo que nos fijaremos también en la significación de sus parámetros. Cabe mencionar que han sido ajustados teniendo como base la serie ya diferenciada, por lo que aparece el coeficiente de la media (intercept), que en ninguno de los casos resulta ser significativa.

El primer modelo tiene tres parámetros no significativos pertenecientes a la MA (*Moving Average*) de la parte estacional: $\Theta_3$, $\Theta_4$ y $\Theta_5$, que coinciden con el previo análisis del ACF, donde se ha visto que el sexto retraso sobresale notablemente pero ni el tercero ni el cuarto ni el quinto lo hacen.

El segundo modelo propuesto solo tiene un parámetro no significativo $\theta_1$, perteneciente a la MA regular, que tiene un $t$-ratio de aproximadamente $1.64$.

A diferencia de los demás, el tercer modelo no presenta ningún parámetro no significsativo, pero cabe mencionar que la significación del parámetro $\Theta_2$, de la MA estacional, roza el límite con un valor de $2.009$.

El cuarto modelo presenta el parámetro $\theta_1$ no significativo, con un $t$-ratio de aproximadamente $1.58$, y el parámetro $\Phi_1$, de la parte AR (*Auto-Regressive*) estacional, que consta con un $t$-ratio cerca de $1.96$ y que podría considerarse como significativo si fuese necesario, en función del cambio en el AIC suponerlo significativo o no.

Teniendo en cuenta esto, y la comparación de los AIC, hay dos modelos que sobresalen en ambos casos. Estos son el modelo $\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$, y el modelo $\mbox{ARIMA}(2,1,0)(2,1,2)_{12}$, con AIC's $-190.12$ y $-189.7$ respectivamente. Siendo también los dos modelos con una mejor significación de parámetros. Tales modelos pasarán a la fase de estimación y validación a continuación.

### Estimación Modelo 1

El Modelo 1 $\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$ es de la forma:

$$(1 - \phi_1 B - \phi_2 B^2)(1 - \Phi_1 B^{12} - \Phi_2 B^{24} - \Phi_3 B^{36} - \Phi_4 B^{48})(1-B)(1-B^{12})\frac{(X_t - \mu_1)^\lambda-1}{\lambda} = (1+ \theta_1 B)Z_t$$

Para la estimación del Modelo 1 se ha de comprobar primeramente si la media de la serie es significativa o no.

Se comprueba la significación de $\hat{\mu_1}$ mediante su $t$-ratio para determinar si es significante para el modelo, es decir, si se rechaza o no la hipótesis nula de que la media es igual a 0.

$$H_0: \hat{\mu_1} = 0 \\ H_1: \hat{\mu_1} \neq 0$$

donde el $t$-ratio viene dado por

$$t = \frac{\hat{\mu_1}}{S_{W_t}} \sim N(0,1)$$

asintóticamente normal al tratarse de un estimador calculado a partir del estimador de máxima verosimilitud. Para no poder rechazar la hipótesis nula, si queremos un nivel de confianza del 95%, el valor absoluto del t-ratio tendrá que ser menor que 2.

```{r}
m1 = arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(4,0,0), period=12))
m1
```

```{r}
cat("Is the mean significant?",abs(m1$coef[8]/sqrt(diag(m1$var.coef)[8])) > 2)
```

Al no tener significación la media de la serie $\hat{\mu_1}$, se puede aplicar la función `arima` a la serie después de la transformación *Box-Cox*, aplicandole las diferenciaciones como parámetros a la función, de esta manera se evitan deshacer las transformaciones después y se puede predecir directamente sobre la serie transformada sin diferenciaciones. Es preciso saber que si que se deberá deshacer la transformación *Box-Cox* para tener las predicciones sobre la serie original.

```{r}
m1 = arima(bcser, order=c(2,1,1), seasonal=list(order=c(4,1,0), period=12))
m1
```

Verificamos que la decisión de retirar la media del modelo ha sido la adecuada ya que obtenemos un AIC menor, lo que indica la mejoría del ajuste. Además como $\hat{\mu_1}$ no es significativa, se ve que los valores de los estimadores de los coeficientes del modelo no han variado en gran escala, al igual que sus desviaciones estandar.

Bajo la misma hipótesis, se comprobará la significación de los estimadores del modelo.

```{r}
cat("\nT-ratios:",round(m1$coef/sqrt(diag(m1$var.coef)),2))
```

Se observa que el estimador del parámetro $\hat{\theta_1}$, tal y como se vió en el apartado anteriror, está por debajo del borde del intervalo de confianza, por lo que ajustaremos un modelo eliminandolo y se compararán ambos modelos en terminos de su AIC.

```{r}
arima(bcser, order=c(2,1,1), seasonal=list(order=c(4,1,0), period=12),
           fixed=c(NA,NA,0,NA,NA,NA,NA))
```

En vista de que el AIC ha aumentado tras eliminar $\hat{\theta_1}$, se considerará que el modelo incial es más adecuado.

El resto de parámetros si son significativos, como se ha visto anteriormente, con lo que el modelo estimado $\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$ resultante es:

$$(1 + 0.7602 B + 0.3825 B^2)(1 + 0.5954 B^{12} + 0.6411 B^{24} + 0.4560 B^{36} + 0.4251 B^{48})(1-B)(1-B^{12})\frac{(X_t - \mu_1)^\lambda-1}{\lambda} = (1 + 0.2315 B)Z_t$$

### Estimación Modelo 2

El Modelo 2 $\mbox{ARIMA}(2,1,0)(2,1,2)_{12}$ es de la forma:

$$(1 - \phi_1 B - \phi_2 B^2)(1 - \Phi_1 B^{12} - \Phi_2 B^{24})(1-B)(1-B^{12})\frac{(X_t - \mu_2)^\lambda-1}{\lambda} = (1+ \Theta_1 B^{12} + \Theta_2 B^{24})Z_t$$

Se repetirán los mismos pasos que con el Modelo 1, comenzando por ajustar el modelo sobre la serie ya diferenciada para ver si la media es significativa.

```{r}
m2 = arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(2,0,2), period=12))
m2
```

```{r}
cat("Is the mean significant?",abs(m2$coef[7]/sqrt(diag(m2$var.coef)[7])) > 2)
```

Se confirma el hecho que ya se había observado en el apartado de Modelos Propuestos, la media no es significativa. Ahora es correcto ajustar el modelo con las diferenciaciones como parámetros de la función *arima*:

```{r}
m2 = arima(bcser, order=c(2,1,0), seasonal=list(order=c(2,1,2), period=12))
m2
```

La disminución del AIC muestra que es acertado suponer que la media no es significativa. Esto también se observa en los valores de los coeficientes del modelo, que apenas varían tras la eliminación de la media.

El siguiente paso es ver si el resto de los coeficientes son significativos.

```{r}
cat("\nT-ratios:",round(m2$coef/sqrt(diag(m2$var.coef)),2))
```

Fijandóse en los T-ratios, se contempla que todos tienen un valor absoluto por encima de 2, indicando que el resto de parámetros si tienen significación en el modelo.

## Validación

... (10 de 4)

### Varianza constante de residuos

A modo de validar la condición de homocedasticidad (varianza constante) en los residuos, nos apoyaremos en el gráfico de estos con la intención de detectar si el modelo captura completamente la estructura de la serie temporal. Si los modelo es correcto en este aspecto, se esperan encontrar gráficos de los residuos similares a un ruido blanco, es decir, sin una gran cantidad de outliers que sobrepasen las bandas de probabilidad, sin una tendencia clara (aspecto que a priori ha sido tratado con la transformación *Box-Cox*), y sin clústeres de volatilidad que anulen la hipótesis de varianza constante.

#### Modelo 1

Observamos que los residuos del Modelo 1 presentan dos valores por debajo del límite inferior de las bandas de probabilidad, lo cual respecta a $0.833%$ de los valores. A pesar de que no es un porcentaje elevado respecto a lo que consideramos indicativo de un problema, estos posibles valores atípicos del modelo serán comentados a profundidad en el apartado de tratamiento de atípicos si este modelo es escogido como el más adecuado.

En términos de la varianza, vemos una dispersión de los residuos alrededor del 0 sin ningún patrón claro y sin presencia de los ya mencionados clústeres o grupos de volatilidad ya que no hay evidencias visuales de fluctuación de la variailidad en periodos de tiempo determinados.

```{r}
resi1 <- resid(m1)
resi1 <- window(resi1, start=c(2000,2))
```

```{r}
p1 = plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~resi1,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 1'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~-3*sd(resi1),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~3*sd(resi1),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 1 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

p2 = ggplotly(ggplot(data=NULL, aes(x=time(d1d12bcser), y=abs(resi1))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 1)") +
  ggtitle(" <b> Absolute value of model 1 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5)))

f13 = subplot(p1, p2, nrows=2, shareX = T) %>%
  layout(title='<b> Constant Variance plots <b>')
f13

scatter.smooth(sqrt(abs(resi1)), lpars = list(col=2))
```

No obstante, la varianza de los residuos no se puede declarar constante, dado que en el desenlace de las muestras se observa una varianza creciente en comparación con los residuos en el inicio de la serie. Comprobamos este hecho mediante un ajuste local suave de le la variabilidad, en donde la linea de ajuste muestra una leve forma sinusoidal a lo largo de los residuos que tiene pendiente positiva hacia el final y con una tendencia general ligeramente lineal con pendiente positiva. Además, los intervalos de confianza de mayor amplitud se encuentran al inicio y hacia el final de las observaciones. No obstante, como ya se ha explicado, la tendencia observada es muy leve y no debería supone un gran problema.

Entonces, la condición de varianza constante para el modelo 1 no es definitiva, como consecuencia principalmente de la presencia de outliers. Después de la aplicación del tatamiento de atípicos se espera una mejora considerable.

#### Modelo 2

```{r}
resi2 <- resid(m2)
resi2 <- window(resi2, start=c(2000,2))
```

```{r}
p1 = plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~resi2,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 2'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~-3*sd(resi2),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~3*sd(resi2),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 2 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

p2 = ggplotly(ggplot(data=NULL, aes(x=time(d1d12bcser), y=abs(resi2))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 2)") +
  ggtitle(" <b> Absolute value of model 2 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5)))

f14 = subplot(p1, p2, nrows=2, shareX = T) %>%
  layout(title='<b> Constant Variance plots <b>')
f14
```

Para el segundo modelo la presencia de outliers ha aumentado, siendo 3 esta vez, el resto de factores, como la tendencia del ajuste local suave y sus intervalos de coanfianza tienen un comportamiento muy similar a los del modelo 1.

Así pues, la hipótesis de homocedasticidad tampoco se puede establecer como definitva en este caso. Puesto a que ambos modelos tienen condiciones similares respecto a la varianza pero el segundo modelo cuenta con más atípicos, se considera que el primer modelo valida mejor que el segundo la hipótesis de varianza constante.

### Hipótesis de normalidad de residuos

Para analizar si se cumple esta segunda hipótesis se utilizaran herramientas como el *Normal Q-Q* plot, el histograma de los residuos o el test de *Shapiro-Wilk*. Debe ponerse el foco sobretodo sobretodo en la primera y última herramientas, pues el histograma de los residuos puede variar en función de la anchura de cada barra y se usará simplemente como una intuición que luego se podrá confirmar con el resto de instrumentos.

#### Modelo 1

Tal y como se detectó en el ánalisis de la varianza, hay presencia de posibles outliers, que en algunos casos incluso sobrepasan los intervalos de confianza del gráfico de cuartiles. Por otro lado, es razonable decir que la normalidad de los reiduos es bastante evidente, pues las muestras se ajustan adecuadamente a los cuantiles teóricos bajo la distribución de la normalidad y la cantidad de posibles outliers no es lo suficientemente elevada ni su magnitud tan pronunciada como para considerar la presencia de *Heavy-Tails* que indicarían volatilidad.

```{r}
f15 = ggplot(data=NULL, aes(sample=resi1)) +
  stat_qq_band(color='#1F968BFF', fill='#1F968BFF', alpha=0.3) +
  stat_qq_line(color='#39568CFF') +
  stat_qq_point(color="#440154FF", fill='#3b528b', shape=21) +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5))
f15
```

Se aprecia visualmente cierta simetría en el histograma de los residuos, que parecen seguir de forma aceptable una distribución normal. Tras realizar el test de *Shapiro-Wilk* se observa que el *pvalor* del test es superior al grado de significación, por lo que se concluye como correcta la decisión de asumir la normalidad de los residuos.

```{r}
hist(resi1,breaks=20, freq=FALSE)
d <- curve(dnorm(x, mean=mean(resi1), sd=sd(resi1)), col=2, add=T)

f16 = plot_ly() %>%
  add_histogram(x=~resi1,
        name="Model 1 residuals",
        marker = list(color = "#22a884",
                      line = list(color = "#2a788e", width = 2))
        ) %>%
  add_trace(x=~d$x, y=~d$y,
            type = 'scatter',
            mode = 'none',
            name = "Density curve",
            fill = "tozeroy",
            fillcolor="rgba(168, 216, 234, 0.5)",
            yaxis = "y2"
            ) %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right", title = "",
                       zeroline = FALSE,
                       showline = FALSE,
                       showticklabels = FALSE,
                       showgrid = FALSE),
         title='<b> Histogram of model 1 residuals <b>',
         xaxis=list(title='Residuals'),
         yaxis=list(title='Density')
         )
f16
```

```{r}
shapiro.test(resi1)
```

#### Modelo 2

El segundo modelo presenta una presencia de outliers más alta y acentuada que el primer modelo, hecho que ya se había vislumbrado con el análisis de la varianza. Sin embargo, tal y como sucede con el primer modelo, parece que el ajuste a los cuantiles teóricos es aceptable puesto que los outliers serán tratados posteriormente si el modelo es seleccionado.

```{r}
f17 = ggplot(data=NULL, aes(sample=resi2)) +
  stat_qq_band(color='#1F968BFF', fill='#1F968BFF', alpha=0.3) +
  stat_qq_line(color='#39568CFF') +
  stat_qq_point(color="#440154FF", fill='#3b528b', shape=21) +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5))
f17
```

A diferencia del modelo anterior, este histograma flaquea más visulamente ya que apenas hay valores entre $-0.3$ y $-0.2$ que puedan sostener la hipótesis de normalidad. Al realizar el test de *Shapiro-Wilk* se confirma que la hipótesis de normalidad no se puede afirmar para este modelo ya que el *pvalor* del test es inferior al nivel de significación $0.05$.

```{r}
hist(resi2,breaks=20, freq=FALSE)
d <- curve(dnorm(x, mean=mean(resi2), sd=sd(resi2)), col=2, add=T)

f18 = plot_ly() %>%
  add_histogram(x=~resi2,
        name="Model 1 residuals",
        marker = list(color = "#22a884",
                      line = list(color = "#2a788e", width = 2))
        ) %>%
  add_trace(x=~d$x, y=~d$y,
            type = 'scatter',
            mode = 'none',
            name = "Density curve",
            fill = "tozeroy",
            fillcolor="rgba(168, 216, 234, 0.5)",
            yaxis = "y2"
            ) %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right", title = "",
                       zeroline = FALSE,
                       showline = FALSE,
                       showticklabels = FALSE,
                       showgrid = FALSE),
         title='<b> Histogram of model 2 residuals <b>',
         xaxis=list(title='Residuals'),
         yaxis=list(title='Density')
         )
f18


```

```{r}
shapiro.test(resi2)
```

### Independencia de residuos

La independencia de los residuos se considera la hipótesis más importante o crítica a la hora de validar el modelo. Para este caso, se usarán como herramientas el ACF y PACF de los residuos y el test de Ljung-Box que permite prueba la hipótesis nula de que las autocorrelaciones de los residuos hasta un desfase *k* son conjuntamente iguales a cero; en otras palabras, independientes.

#### Modelo 1

En cuanto a los retrasos estacionales, el retraso número 60 sobresale de los límites de confianza, sin embargo al tratarse de un restraso considerablemente lejos del origen puede considerarse como fruto del azar y no tenerse en cuenta. Esta suposición se confirma con el el test estadistico de Ljung-Box, que muestra que el p-valor de la hipótesis en ese desafes está por encima del nivel de significación. Con respecto a la componente regular de los residuos, se puede afirmar que presentan una estructura similar a un *White Noise*, ya que no presentan significación alguna, ni cerca ni lejos del origen (algunas observaciones rozan o sobrsalen ligeramente, pero Ljung-Box confirma que pueden considerarse fruto del azar).

```{r}
resi1 <- resid(m1)
f19 = ts_cor(resi1, lag.max = 72)
f19
```

Además de la interpretación visual del ACF y PACF de los residuos, los pvalores del test de Ljung-Box están por encima en todos los casos del nivel de significación. Por lo que se confirma la hipótesis de independencia de residuos para el Modelo 1.

```{r}
tsdiag(m1,gof.lag=72)
```

#### Modelo 2

EN el segundo modelo, destaca el restraso número 23 que sobresale de forma notable en ambos gráficos. También se pueden destacar las observaciones 16, 46 y 72 que rozan incluso sobrepasan las bandas. Dejando esto de lado, tanto ACF y PACF se asemejan considerablemente bien a los propios de un *White Noise*.

Para

```{r}
f20 = ts_cor(resi2, lag.max = 72)
f20
```

Para comprobar los desfases se utilizará nuevamente el test de Ljung-Box. El test muestra que la observación 23 (24 en el gráfico, pues se empieza desde la muestra 1) posee un p-valor superior al nivel de signifcación. Lo mismo sucede con las demás a excepción de la número 72, que se encuentra por debajo y no puede ser pasada por alto. A pesar de ser una observación lejana, este hecho podría dar indicios de que la hipótesis de independencia no se cumple tan bien como en el primer modelo, en el que para todos los residuos no puede ser rechazada la hipótesis de independencia.

```{r}
tsdiag(m2,gof.lag=72)
```

## Propiedad de causalidad y/o invertibilidad

A fin de comprobar la causalidad de un modelo se ha de comprobar que los pesos $\psi_i$ de

$$\phi(B) = \frac{\theta_q(B)}{\phi_p(B)}$$

converjan, de modo que se pueda expresar como un $\mbox{MA}(\infty)$. Lo cuál será de gran utilidad a la hora del cálculo de la varianza de las predicciones puntuales realizadas en breve.

Para asegurar la invertibilidad de un modelo, se ha de comprobar, de manera análoga, que los pesos $\pi_i$ de

$$\pi(B) = \frac{\phi_p(B)}{\theta_q(B)}$$ tengan convergencia, de modo que se obtenga una expresión $\mbox{AR}(\infty)$. Bajo esta propiedad y con el uso de observaciones pasadas será posible el cálculo de las predicciones puntuales en el apartado de predicciones.

### Modelo 1

Al ver que todas las raices del polinomio de grado $50$ son mayores que la unidad, podemos confirmar que el Modelo 1 es causal.

```{r}
Mod(polyroot(c(1,-m1$model$phi)))
```

Como solo hay una raíz para la componente de media móvil del modelo y tiene módulo mayor que 1, el Modelo 1 también cumple con la caondición de invertible.

```{r}
Mod(polyroot(c(1,m1$model$theta)))
```

```{r}
f21 = ggplotly(autoplot(m1) +
  geom_point(color="#440154", fill='#414487', shape=21, size=1) +
  theme_bw() +
  ggtitle(" <b> Invers roots model 1 <b>") +
  theme(plot.title = element_text(hjust = 0.5)))
f21
```

Se comprueba visualmente que, en este caso, la inversa de las raices de los dos polinomios caen dentro del circulo unitario, por lo tanto, el Modelo 1 es tanto causal como invertible.

### Modelo 2

Nuevamente comprobamos que todas las raíces, tanto del polinomio de la parte AR como las del polinomio de la parte MA son superiores a 1. Por tanto, podemos afirmar que el modelo es respectivamente causal y invertible

```{r}
Mod(polyroot(c(1,-m2$model$phi)))
```

```{r}
Mod(polyroot(c(1,m2$model$theta)))
```

Para visualizar este resultado, se usa la inversa de las raíces y se comprueba que todas se encuentran dentro del círculo unidad.

```{r}
f22 = ggplotly(autoplot(m2) +
  geom_point(color="#440154", fill='#414487', shape=21, size=1) +
  theme_bw() +
  ggtitle(" <b> Invers roots model 1 <b>") +
  theme(plot.title = element_text(hjust = 0.5)))
f22
```

## Estabilidad

Para poder comprobar si los modelos son estables se debe verificar que el modelo propuesto para todas las observaciones de la serie temporal es similar, en cuanto a unas condiciones cualitativas, al modelo de *training*, conformado por la serie temporal sin las 12 últimas muestras.

Por lo que se ha de comprobar si, al ajustar cada modelo con la serie recortada se mantienen unos coeficientes muy similares con respecto a la magnitud, al signo y a su significación.

```{r}
last=c(2017,12); train=window(ser, end=last)
```

### Modelo 1

```{r}
bctrain = (train^lambda-1)/lambda

m1_train <- arima(bctrain, order=c(2,1,1),
                  seasonal=list(order=c(4,1,0), period=12))
m1_train
m1
```

Como se puede advertir, para el modelo 1, se mantienen los signos de los coeficientes y los errores y, además, las magnitudes de estos son muy similares, siendo las variaciones más significativas de apenas una centésima.

```{r}
cat("\nT-ratios:",round(m1_train$coef/sqrt(diag(m1_train$var.coef)),2))
cat("\nT-ratios:",round(m1$coef/sqrt(diag(m1$var.coef)),2))
```

Para corroborar finalmente al estabilidad del modelo, hay que fijarse en que la significación de los parámetros apenas ha variado.

### Modelo 2

Respecto al segundo modelo, a pesar que los signos no cambian, las magnitudes de los coeficientes varian de mucho más considerablemente que para el primer modelo.

```{r}
m2_train <- arima(bctrain, order=c(2,1,0),
                  seasonal=list(order=c(2,1,2), period=12))
m2_train
m2
```

```{r}
cat("\nT-ratios:",round(m2_train$coef/sqrt(diag(m2_train$var.coef)),2))
cat("\nT-ratios:",round(m2$coef/sqrt(diag(m2$var.coef)),2))
```

Lo mismo sucede con las significaciones, que también presentan variaciones más drásticas a pesar de no cambiar el signo. Esto indica que el modelo 1 es más estable que el modelo 2.

## Predicciones

Como el propósito del estudio explica, el objetivo es poder realizar predicciones de futuros valores de la serie temporal, conocida su última observación. Para lo cual, ene este caso se realizarán las predicciones puntuales de las últimas 12 observaciones separadas previamente, para comprobar el ajuste y analizar los intervalos de confianza.

Se inicia obteniendo las predicciones mediante la función `predict`. Tengase en cuenta que al haber realizado una transformación *Box-Cox* al incio de la identificación, será necesario deshacer estar predicciones a las 12 obserevaciones predecidas, al igual que a los límites del intervalo de confianza.

Los cuales son computados mediante:

$$IC(X_{t+h})_{1-\alpha} = \tilde{X}_{t+h} \pm Z_{1-\alpha/2}\sqrt{\mbox{Var}(\tilde{X}_{t+h})} \ \ , \ h = \lbrace 1, ..., 12\rbrace$$

#### Modelo 1

```{r}
pre1 = predict(m1_train, n.ahead=12)

pr1 = (lambda*(pre1$pred)+1)^(1/lambda)

tl1 = pre1$pred - qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*pre1$se
tl1 = (lambda*(tl1)+1)^(1/lambda)

tu1 = pre1$pred + qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*pre1$se
tu1 = (lambda*(tu1)+1)^(1/lambda)
```

```{r}
f23 = plot_ly(x=~time(ser), y=~ser,
        type = "scatter",
        mode = "lines+markers",
        line = list(color="#2a788e"),
        marker = list(color="#2a788e"),
        name = "Observed"
        ) %>%
  add_trace(x = window(time(ser), start=c(2018,1)),
            y = pr1,
            line = list(color="rgb(68, 1, 84)", dash = "dash"),
            marker = list(color="rgb(68, 1, 84)"),
            name = "Predicted"
            )%>%
  add_ribbons(x = window(time(ser), start=c(2018,1)),
              ymin=tl1, ymax=tu1,
              line = list(color = 'rgba(34, 168, 132, 0.2)'),
              fillcolor = 'rgba(34, 168, 132, 0.2)',
              name = "95% confidence",
              inherit = FALSE
              ) %>%
  layout(title='<b> Prediction for the test set using model 1 <b>',
         xaxis=list(title='Time', range=c(2016,2019)),
         yaxis=list(title='(Thousand million euros)')
         )
f23
```

Tras la predicción del modelo de *training* sobre las 12 observaciones de validación se observa que las predicciones de las muestras se alienean con las muestras observadas. Si bien en ocasiones puntuales difieren, los intervalos de confianza parecen ser considerablemnete reducidos.

Se notá el incremento de la amplitud entre los límites de confianza como es de esperar debido al incremento de la incerteza para predicciones puntuales más alejadas de la última observación.

#### Modelo 2

```{r}
pre2 = predict(m2_train, n.ahead=12)


pr2 = (lambda*(pre2$pred)+1)^(1/lambda)

tl2 = pre2$pred - qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*pre2$se
tl2 = (lambda*(tl2)+1)^(1/lambda)

tu2 = pre2$pred + qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*pre2$se
tu2 = (lambda*(tu2)+1)^(1/lambda)
```

```{r}
f24 = plot_ly(x=~time(ser), y=~ser,
        type = "scatter",
        mode = "lines+markers",
        line = list(color="#2a788e"),
        marker = list(color="#2a788e"),
        name = "Observed"
        ) %>%
  add_trace(x = window(time(ser), start=c(2018,1)),
            y = pr2,
            line = list(color="rgb(68, 1, 84)", dash = "dash"),
            marker = list(color="rgb(68, 1, 84)"),
            name = "Predicted"
            ) %>%
  add_ribbons(x = window(time(ser), start=c(2018,1)),
              ymin=tl2, ymax=tu2,
              line = list(color = 'rgba(34, 168, 132, 0.2)'),
              fillcolor = 'rgba(34, 168, 132, 0.2)',
              name = "95% confidence",
              inherit = FALSE
              ) %>%
  layout(title='<b> Prediction for the test set using model 2 <b>',
         xaxis=list(title='Time', range=c(2016,2019)),
         yaxis=list(title='(Thousand million euros)')
         )
f24
```

## Selección

LLegados a este punto del análisis, se tiene que escoger un único modelo de entre los dos propuestos para proceder a afinarlo con el tratamiento de efectos de calendario y seguidamente el tratamiento de outliers.

Para este proceso de selección nos apoyaremos en distintas medidas, desde adecuación hasta predicción de los datos. Incluyendo también una discusión en terminos de las hipótesis verificadas en el apartado de validación.

### Medidas de capacidad de predicción

```{r}
start=c(2017,12); last=c(2018,12);
obs = window(ser, start = start, end = last)
```

Se ve clara la diferencia entre los valores para los errores del modelo 1 y el modelo 2. La calidad de predicción del modelo 1 es superior, ya que los valores de los errores para este modelo son menores.

#### Modelo 1

```{r}
cat("RMSPE1: ", sqrt(mean(((obs-pr1)/obs)^2)), "\n")
cat("MAPE1: ", mean(abs(obs-pr1)/obs))
```

#### Modelo 2

```{r}
cat("RMSPE2: ", sqrt(mean(((obs-pr2)/obs)^2)), "\n")
cat("MAPE2: ", mean(abs(obs-pr2)/obs))
```

### Intervalos de confianza

#### Modelo 1

```{r}
cat("Mean length of IC for model 1: ",mean(tu1-tl1))

```

#### Modelo 2

```{r}
cat("Mean length of IC for model 2: ",mean(tu2-tl2))
```

En cuanto a la media de los intervalos, el modelo 2 presenta una distancia entre los dos límites del intervalo más pequeña,

MEJORES INTERVALOS EN M2, PERO LA varianza NO ES CONSTANTE XD

### Medidas de adecuación a los datos

```{r}
cat("AIC Modelo 1: ", AIC(m1), "\n")
cat("AIC Modelo 2: ", AIC(m2), "\n")
cat("BIC Modelo 1: ", BIC(m1), "\n")
cat("BIC Modelo 2: ", BIC(m2), "\n")
```

## Tratamiento de efectos de calendario

...

```{r}
source("Practicas/calendarEffects.r")
```

...

```{r}
length(ser)
```


```{r}
start = c(1999,1,length(ser))
vEa = Weaster(start)
# vEa
```

...

```{r}
vTD = Wtrad(start)
# vTD
```

```{r}
m1
```

...

```{r}
m1Ea = arima(bcser, order=c(2,1,1),
             seasonal=list(order=c(4,1,0), period=12),
             xreg = data.frame(vEa))
m1Ea
```

...

```{r}
m1TD = arima(bcser, order=c(2,1,1),
             seasonal=list(order=c(4,1,0), period=12),
             xreg = data.frame(vTD))
m1TD
```

...

```{r}
m1EC = arima(bcser, order=c(2,1,1),
             seasonal=list(order=c(4,1,0), period=12),
             xreg = data.frame(vEa,vTD))
m1EC
```


```{r}
# coef(m1EC)["vEa"]*vEa
```


```{r}
# coef(m1EC)["vTD"]*vTD
```

...

```{r}
bcserEC = bcser - coef(m1EC)["vEa"]*vEa - coef(m1EC)["vTD"]*vTD
# (lambda*(cbind(bcser, bcserEC))+1)^(1/lambda)
```


## Re-identificación modelo

```{r}
m <- apply(matrix(bcserEC, nrow=12), 2, mean)
v <- apply(matrix(bcserEC, nrow=12), 2, var)

f25 = plot_ly(x=~m, y=~v,
        marker = list(size = 7,
                      color = '#2a788e',
                      line = list(color = '#414487',width = 1))
        ) %>%
  layout(title='<b> Varience~Mean <b>',
         xaxis=list(title='Mean'),
         yaxis=list(title='Variance'))
f25
```


```{r}
f26 = ts_seasonal(bcserEC, type="all", title=" <b> Seasonality plot for Time Series <b>")
f26
```

```{r}
d12bcserEC = diff(bcserEC, 12)
```

```{r}
f27 = plot_ly() %>%
  add_trace(x=~time(d12bcserEC), y=~d12bcserEC,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d12bcserEC), y=~mean(d12bcserEC),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Time Series <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
f27
```


```{r}
var(d12bcserEC)
var(diff(d12bcserEC))
var(diff(diff(d12bcserEC)))
```

```{r}
d1d12bcserEC = diff(d12bcserEC)
```

```{r}
f28 = plot_ly() %>%
  add_trace(x=~time(d1d12bcserEC), y=~d1d12bcserEC,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d1d12bcserEC), y=~mean(d1d12bcserEC),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Stationary Time Series <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
f28
```


```{r}
var(d1d12bcser)
var(d1d12bcserEC)
```



```{r}
f29 = ts_cor(d1d12bcserEC, lag.max = 72)
f29
```

```{r}
arima(d1d12bcserEC,order=c(0,0,1),
           seasonal=list(order=c(0,0,1),period=12))
```


```{r}
arima(d1d12bcserEC,order=c(2,0,0),
           seasonal=list(order=c(0,0,1),period=12))
```


```{r}
mEC = arima(bcserEC,order=c(2,1,0),
           seasonal=list(order=c(0,1,1),period=12))
mEC
```


## Estimación modelo con efectos de calendario

...

```{r}
cat("\nT-ratios:",round(mEC$coef/sqrt(diag(mEC$var.coef)),2))
```

...

## Validación

...

### Varianza constante de residuos

...

```{r}
resiEC <- resid(mEC)
resiEC <- window(resiEC, start=c(2000,2))
```

```{r}
p1 = plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~resiEC,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 1'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~-3*sd(resiEC),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~3*sd(resiEC),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 1 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

p2 = ggplotly(ggplot(data=NULL, aes(x=time(d1d12bcserEC), y=abs(resiEC))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 1)") +
  ggtitle(" <b> Absolute value of model 1 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5)))

f30 = subplot(p1, p2, nrows=2, shareX = T) %>%
  layout(title='<b> Constant Variance plots <b>')
f30
```

...

### Hipótesis de normalidad de residuos

...

```{r}
f31 = ggplot(data=NULL, aes(sample=resiEC)) +
  stat_qq_band(color='#1F968BFF', fill='#1F968BFF', alpha=0.3) +
  stat_qq_line(color='#39568CFF') +
  stat_qq_point(color="#440154FF", fill='#3b528b', shape=21) +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5))
f31
```

...

```{r}
f32 = plot_ly() %>%
  add_histogram(x=~resiEC,
        name="Model 1 residuals",
        marker = list(color = "#22a884",
                      line = list(color = "#2a788e", width = 2))
        ) %>%
  add_trace(x=~d$x, y=~d$y,
            type = 'scatter',
            mode = 'none',
            name = "Density curve",
            fill = "tozeroy",
            fillcolor="rgba(168, 216, 234, 0.5)",
            yaxis = "y2"
            ) %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right", title = "",
                       zeroline = FALSE,
                       showline = FALSE,
                       showticklabels = FALSE,
                       showgrid = FALSE),
         title='<b> Histogram of model 1 residuals <b>',
         xaxis=list(title='Residuals'),
         yaxis=list(title='Density')
         )
f32
```

```{r}
shapiro.test(resiEC)
```

...

### Independencia de residuos

...

```{r}
resiEC <- resid(mEC)
f33 = ts_cor(resiEC, lag.max = 72)
f33
```

...

```{r}
tsdiag(mEC,gof.lag=72)
```

...

## Propiedad de causalidad y/o invertibilidad


```{r}
Mod(polyroot(c(1,-mEC$model$phi)))
```

```{r}
Mod(polyroot(c(1,mEC$model$theta)))
```

```{r}
f21 = ggplotly(autoplot(mEC) +
  geom_point(color="#440154", fill='#414487', shape=21, size=1) +
  theme_bw() +
  ggtitle(" <b> Invers roots model <b>") +
  theme(plot.title = element_text(hjust = 0.5)))
f21
```

## Estabilidad

```{r}
last=c(2017,12); bctrainEC=window(bcser, end=last)
```

```{r}
mEC_train <- arima(bctrainEC, order=c(2,1,0),
                  seasonal=list(order=c(0,1,1), period=12))
mEC_train
mEC
```

```{r}
cat("\nT-ratios:",round(mEC_train$coef/sqrt(diag(mEC_train$var.coef)),2))
cat("\nT-ratios:",round(mEC$coef/sqrt(diag(mEC$var.coef)),2))
```

## Predicciones

```{r}
preEC = predict(mEC_train, n.ahead=12)

pr1 = (lambda*(preEC$pred)+1)^(1/lambda)

tl1 = preEC$pred - qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*preEC$se
tl1 = (lambda*(tl1)+1)^(1/lambda)

tu1 = preEC$pred + qnorm(1-0.05/2,mean = 0,sd = 1,lower.tail = TRUE)*preEC$se
tu1 = (lambda*(tu1)+1)^(1/lambda)
```

```{r}
f23 = plot_ly(x=~time(bcserEC), y=~bcserEC,
        type = "scatter",
        mode = "lines+markers",
        line = list(color="#2a788e"),
        marker = list(color="#2a788e"),
        name = "Observed"
        ) %>%
  add_trace(x = window(time(bcserEC), start=c(2018,1)),
            y = pr1,
            line = list(color="rgb(68, 1, 84)", dash = "dash"),
            marker = list(color="rgb(68, 1, 84)"),
            name = "Predicted"
            )%>%
  add_ribbons(x = window(time(bcserEC), start=c(2018,1)),
              ymin=tl1, ymax=tu1,
              line = list(color = 'rgba(34, 168, 132, 0.2)'),
              fillcolor = 'rgba(34, 168, 132, 0.2)',
              name = "95% confidence",
              inherit = FALSE
              ) %>%
  layout(title='<b> Prediction for the test set using model <b>',
         xaxis=list(title='Time', range=c(2016,2019)),
         yaxis=list(title='(Thousand million euros)')
         )
f23
```


## Selección

LLegados a este punto del análisis, se tiene que escoger un único modelo de entre los dos propuestos para proceder a afinarlo con el tratamiento de efectos de calendario y seguidamente el tratamiento de outliers.

Para este proceso de selección nos apoyaremos en distintas medidas, desde adecuación hasta predicción de los datos. Incluyendo también una discusión en terminos de las hipótesis verificadas en el apartado de validación.

### Medidas de capacidad de predicción

```{r}
start=c(2017,12); last=c(2018,12);
obs = window(ser, start = start, end = last)
```

Se ve clara la diferencia entre los valores para los errores del modelo 1 y el modelo 2. La calidad de predicción del modelo 1 es superior, ya que los valores de los errores para este modelo son menores.

#### Modelo 1

```{r}
cat("RMSPE1: ", sqrt(mean(((obs-pr1)/obs)^2)), "\n")
cat("MAPE1: ", mean(abs(obs-pr1)/obs))
```

#### Modelo 2

```{r}
cat("RMSPE2: ", sqrt(mean(((obs-pr2)/obs)^2)), "\n")
cat("MAPE2: ", mean(abs(obs-pr2)/obs))
```

### Intervalos de confianza

#### Modelo 1

```{r}
cat("Mean length of IC for model 1: ",mean(tu1-tl1))

```

#### Modelo 2

```{r}
cat("Mean length of IC for model 2: ",mean(tu2-tl2))
```

En cuanto a la media de los intervalos, el modelo 2 presenta una distancia entre los dos límites del intervalo más pequeña,

MEJORES INTERVALOS EN M2, PERO LA varianza NO ES CONSTANTE XD

### Medidas de adecuación a los datos

```{r}
cat("AIC Modelo 1: ", AIC(m1), "\n")
cat("AIC Modelo 2: ", AIC(m2), "\n")
cat("BIC Modelo 1: ", BIC(m1), "\n")
cat("BIC Modelo 2: ", BIC(m2), "\n")
```


## Tratamiento de atípicos

...

## Re-identificación modelo

```{r}
ts_cor(d1d12bcser, lag.max = 72)
```

## Estimación modelo con efectos de calendario

...

```{r}

```

...

```{r}
cat("\nT-ratios:",round(m$coef/sqrt(diag(m$var.coef)),2))
```

...

```{r}

```

...

## Validación

...

### Varianza constante de residuos

...

```{r}
resi <- resid(m)
resi <- window(resi, start=c(2000,2))
```

```{r}
p1 = plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~resi,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 1'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~-3*sd(resi),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(d1d12bcser), y=~3*sd(resi),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 1 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

p2 = ggplotly(ggplot(data=NULL, aes(x=time(d1d12bcser), y=abs(resi))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 1)") +
  ggtitle(" <b> Absolute value of model 1 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5)))

subplot(p1, p2, nrows=2, shareX = T) %>%
  layout(title='<b> Constant Variance plots <b>')

scatter.smooth(sqrt(abs(resi)), lpars = list(col=2))
```

...

### Hipótesis de normalidad de residuos

...

```{r}
ggplot(data=NULL, aes(sample=resi)) +
  stat_qq_band(color='#1F968BFF', fill='#1F968BFF', alpha=0.3) +
  stat_qq_line(color='#39568CFF') +
  stat_qq_point(color="#440154FF", fill='#3b528b', shape=21) +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5))
```

...

```{r}
plot_ly() %>%
  add_histogram(x=~resi,
        name="Model 1 residuals",
        marker = list(color = "#22a884",
                      line = list(color = "#2a788e", width = 2))
        ) %>%
  add_trace(x=~d$x, y=~d$y,
            type = 'scatter',
            mode = 'none',
            name = "Density curve",
            fill = "tozeroy",
            fillcolor="rgba(168, 216, 234, 0.5)",
            yaxis = "y2"
            ) %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right", title = "",
                       zeroline = FALSE,
                       showline = FALSE,
                       showticklabels = FALSE,
                       showgrid = FALSE),
         title='<b> Histogram of model 1 residuals <b>',
         xaxis=list(title='Residuals'),
         yaxis=list(title='Density')
         )
```

```{r}
shapiro.test(resi)
```

...

### Independencia de residuos

...

```{r}
resi <- resid(m)
ts_cor(resi, lag.max = 72)
```

...

```{r}
tsdiag(m1,gof.lag=72)
```

...

# Conclusiones y discusión

...

# Bibliografía

...

.

```{r}
# rm(f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24)

# f = list(f25,f26,f27,f28,f29,f30,f31,f32,f33)
# n = length(f)
# for (i in 1:n) {
#   orca(f[[i]], paste0("./f",i,".png"))
#   cat(i)
# }
```
