---
title: "Project"
author: "Juan Pablo Zaldivar && Enric Millan"
date: "2023-03-14"
output: pdf_document
---

la, residuos en 0, obs neg

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo=FALSE) 
```

```{r}
library(car)
library(qqplotr)
library(plotly)
library(forecast)
library(TSstudio)
```

```{r}
m <- list(l = 50, r = 50, b = 100, t = 100, pad = 4)
```

# Titulo

...

# Indice

...

# Introducción

El propósito al estudio de este proyecto consiste en obtener previsiones a partir de la última observación registrada de una serie temporal seleccionada. No sin antes haber realizado un análisis e informe exhaustivos acerca de la observaciones de la serie y sus propiedades.

Tal estudio presentado a continuación se compone de una succesión de apartados en donde se empleará la metodología Box-Jenkins mediante modelos ARIMA que representen la serie temporal, así como también la incorporación del tratamiento de observaciones atípicas.

## Descripción Serie Temporal

La serie temporal de eleccíon para el presente proyecto contiene el total de exportaciones (en miles de millones de euros) en España. (CITA).

*(descripcion serie, metodo de recogida de datos, variables)*

Con un total de 240 observaciones de frecuencia mensual, recorre un periodo de 20 años. Desde el primer mes de 1999 hasta diciembre de 2018. Los valores de las observaciones están registradas en miles de millones de euros, por lo tanto, por simplicidad a la hora de graficar a partir de ahora se trabajara con decenas en términos de miles de de millones.

```{r}
ser <- ts(read.table("Data/export.dat")/1000,start=1999,freq=12)
```

```{r}
plot_ly(x=~time(ser), y=~ser,
        type = "scatter",
        fill="tozeroy",
        mode="lines",
        line = list(color = "#2a788e"),
        fillcolor="rgba(42, 120, 142, 0.5)"
        ) %>% 
  layout(title='<b> Total exportations in Spain <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')
         )
```

Observando la serie temporal detectamos una tendencia creciente a lo largo del tiempo, que mantiene una pendiente casi constante, es decir, no se podría decir que hay indicios de un aumento repentino del total de exportaciones en españa durante las últimas dos décadas.

Por otro lado, a simple vista se detecta una caída en lo que corresponde a los años 2008-2009, muy seguramente debido a la crísis económica. Este hecho probablemente conlleve a un valor atípico en la serie que se tendrá que confirmar en el desarrollo del análsis con el tratamiento de atípicos.

Otro hecho a destacar sobre la serie son un par de observaciones con magnitudes que sobresalen notablemente en el mes de febrero (finales de enero e inicios de febrero) de 2011 y 2017 respectivamente. Una posible hipótesis para la segunda observación (febrero 2017) supone que haya sido causa de un incremento de las exportaciones debido a los terremotos en Filipinas como muestra de apoyo y soliralidad hacía las personas implicadas. Aunque por el valor de la muestra, parece ser causa de un motivo distinto. Para el primer caso (enero/febrero 2011) los bienes de equipo y el sector automóvil han sido los principales impulsores del aumento en los 10 primeros meses del año, por lo que es probable que este pico en febrero esté relacionado. Los datos oficiales indican que en el segundo caso las principales contribuciones al crecimiento de las exportaciones provinieron del sector de productos energéticos, alimentación, bebidas y tabaco, sector automóvil y manufacturas de consumo.

Se ha de aclarar que estas explicaciones se realizan en base a investigaciones propias para interntar tener un un entendimiento de la causa de tales observaciones. El caso ideal sería contar con un experto en el ámbito de la exportación nacional e incluso internacional para otorgarnos una visión clara sobre estos resultados.

```{r}
ds <- decompose(ser)

p1 <- plot_ly() %>% add_trace(x = time(ds$x), y = ds$x,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(34, 168, 132)"),
                              fillcolor="rgba(34, 168, 132, 0.5)",
                              name = "Original Time Series")
p2 <- plot_ly() %>% add_trace(x = time(ds$trend), y = ds$trend,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(42, 120, 142)"),
                              fillcolor="rgba(42, 120, 142, 0.5)",
                              name = "Trend")
p3 <- plot_ly() %>% add_trace(x = time(ds$seasonal), y = ds$seasonal,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(65, 68, 135)"),
                              fillcolor="rgba(65, 68, 135, 0.5)",
                              name = "Seasonal")
p4 <- plot_ly() %>% add_trace(x = time(ds$random), y = ds$random,
                              type = "scatter",
                              mode = "lines",
                              fill="tonexty",
                              line = list(color = "rgb(68, 1, 84)"),
                              fillcolor="rgba(68, 1, 84, 0.5)",
                              name = "Random")

subplot(p1, p2, p3, p4, nrows=4) %>%
  layout(title='<b> Time Series Decomposition <b>')
```

Mediante la descomposición de la serie, confirmamos la tendencia conforme a un creciemiento lineal no excesivamente pronunciado, aunque tengase en cuenta de las magnitudes de las observaciones.

En verde, la componente estacional muestra un pico en el número de exportaciones en el primer cuatrimestre del año, mientras que sufre de una disminución considerable durante la temporada de verano, con el descenso mayor en el mes de agosto aproximadamente. Este último hecho coincide con el periodo de mayor descanso laboral en España.

## Motivación

...

## Metodología

Como ya se ha mencionado en este proyecto se usará la metodología Box-Jenkins.

De manera incial se comenzará con la identificación de la serie. La cual consiste en la evaluación de la serie para aplicarle un conjunto de trasnformaciones de modo que se obtenga una serie estacionaria, sobre la cual poder prpoponer modelos adecuados. Dichas transformaciones se aplican para obtener una variancia cosntante de la serie, eliminar un posible patrón estacional de los datos y conseguir una media constante. De tal forma que sea posible proponer modelos, premiando su baja complejidad, para proceder a la estimación de sus parámetros y de la media de la serie.

Siguientemente, se han de validar los modelos propuestos. Llegados a este punto, trabajaremos con dos modelos propuesto a modo de simplificación del proyecto. Para cada uno de ellos se realizarán las revisiones necesarias para validar la variancia consante de los residuos del modelo. Comprobaremos que los residuos se comporten bajo la hipótesis de normalidad como un *White Noise*. Por último se comprobará que los residuos cumplan con la condición de normalidad, considerada la de mayor relevancia al tratarse de una serie temporal.

Una vez consolidados los modelos propuestos, se estudiarán las propiedades de estabilidad, invertibilidad y causalidad de cada uno. De modo que justo después se realizarán las predicciones puntuales y sus medidas de predicción del modelo.

El estudio de estas predicciones se buscará afinar al aplicar un tratamiento de atípicos, en la cual se busca definir una serie teórica sin estos atípicos para reducir la variabilidad del modelo. A fin de poder mejorar las predicciones en cada uno de los modelos. Para poder así, discutir sobre un mejor modelo en términos de las cualidades y medidas realizadas a lo largo del estudio.

## Descripción sintética

...

# Resultados e interpretación

...

## Identificación

...

### Transformación de la serie

...

#### Variancia constante

Se pretende identificar algun tipo de tendencia en la serie que haga que la variancia no sea constante a lo largo de esto. Para ello se grafican mediciones de la media y la variancia de grupos consecutivos de entre 8-12 observaciones a modo de poder visualizar el comportamiento de la variancia de la serie.

Para satisfacer la condición de variancia constante, la dispersión de los puntos debe ser similar a lo largo de todo el eje horizonal.

```{r}
m <- apply(matrix(ser, nrow=12), 2, mean)
v <- apply(matrix(ser, nrow=12), 2, var)

plot_ly(x=~m, y=~v,
        marker = list(size = 7,
                      color = '#2a788e',
                      line = list(color = '#414487',width = 1))
        ) %>%
  layout(title='<b> Varience~Mean <b>',
         xaxis=list(title='Mean'),
         yaxis=list(title='Variance'))
```

Vease que hay un aumento de la variancia entre los valores inciales y finales de la serie, aunque como se ha comprobado, una trasnformación de tipo logaritmica no es suficiente para el caso de esta serie temporal. Si bien no se podría llegar a razonar y aceptar que todo el conjunto de puntos mantienen una dispersión similar, una transformación *Box-Cox* podría ser útil para este caso.

Para evitar la posible influencia de valores atípicos, también se realiza un boxplot para cada año de la serie, de modo que, idealmente, la altura del IQR de cada caja tiene que se aproximadamente la misma.

Para el caso de esta serie temporal observamos que no hay una gran diferencia en la variabilidad de la serie pero si que es notable en ciertos casos, por lo que no se puede validar que haya una variancia constante en la serie original.

```{r}
plot_ly(x=~floor(time(ser)), y=~ser, type='box',
        boxpoints = 'suspectedoutliers',
        fillcolor="#2a788e",
        line=list(color="#414487")
        ) %>%
  layout(title='<b> Box Plot for periods <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='Time Series'))
```

Aunque la trasnformación logaritmica es de fácil interpretación, comprobamos que no mejora la condición de la variancia y no es suficiente, por lo que se ha de proponer un valor de $\lambda$ para la transformación Box-Cox ya mencionada, que tiene la siguiente forma:

$$\frac{X_t^{\lambda}-1}{\lambda}, \ \ \lambda \in [-1,2], \ \lambda \neq 0$$

```{r}
lambda = BoxCox.lambda(ser, method = c("guerrero", "loglik"), lower = -1, upper = 2)
bcser = (ser^lambda-1)/lambda
```

La función `BoxCox.lambda()` de la librería **forecast** nos permite seleccionar de forma automática la mejor $\lambda$ posible bajo los criterios que se establezcan. En este caso, usando los métodos "*guerrero*" y "*loglik*" se busca, en primer lugar, una $\lambda$ que minimice el coeficiente de variación para la subserie resultante de la transformación y, en segundo lugar, el valor de $\lambda$ se elige para maximizar el perfíl de la verosimilitud logarítmica de un modelo lineal ajustado a x.

QUE VERGAS ES ESTO --\> Para datos no estacionales se ajusta una tendencia lineal en el tiempo, mientras que para datos estacionales se utiliza una tendencia lineal en el tiempo con variables ficticias estacionales.

Con lo que se obtiene un valor de $\lambda = 0.395$ aproximadamente.

```{r}
m <- apply(matrix(bcser, nrow=12), 2, mean)
v <- apply(matrix(bcser, nrow=12), 2, var)

plot_ly(x=~m, y=~v,
        marker = list(size = 7,
                      color = '#2a788e',
                      line = list(color = '#414487',width = 1))
        ) %>%
  layout(title='<b> Varience~Mean <b>',
         xaxis=list(title='Mean'),
         yaxis=list(title='Variance'))
```

```{r}
plot_ly(x=~floor(time(bcser)), y=~bcser, type='box',
        boxpoints = 'suspectedoutliers',
        fillcolor="#2a788e",
        line=list(color="#414487")
        ) %>%
  layout(title='<b> Box Plot for periods <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='Time Series'))
```

```{r}
plot_ly(x=~time(bcser), y=~bcser,
        type = "scatter",
        fill="tozeroy",
        mode="lines",
        line = list(color = "#2a788e"),
        fillcolor="rgba(42, 120, 142, 0.5)"
        ) %>% 
  layout(title='<b> Time series after Box-Cox transformation <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')
         )
```

Tras la transformación, la variancia para los diferentes grupos de observaciones es similar. Además de que la altura de los IQR de los boxplots ya es prácticamente la misma a lo largo del tiempo y en el gráfico de varianza y media vemos que la primera no toma una tendencia en función de la segunda.

#### Patrón estacional

Para buscar un posible patrón estacional de orden $s=12$, se grafícan las subseries correspondientes a cada año de la serie temporal. Además de dos representaciones adicionales, la primera (segundo gráfico) muestra si hay una gerarquía entre los diversos meses pero se ve que no hay ninguno que sobresalga siempre.La segunda (tercer gráfico) muestra los boxplots de las distribuciones de las observaciones por meses.

```{r}
ts_seasonal(bcser, type="all", title=" <b> Seasonality plot for Time Series <b>")

monthplot(bcser)
```

Para cada año se observa una claro patrón estacional en el mes de agosto, donde hay una clara caida de los valores de las observaciones. Esto se confirma observando los boxplots, en los que se aprecia que todos tienen valores similares a excepción agosto, que tiene los valores más bajos, debido a que es el mes clave del periodo vacacional en España, tal y como se había visto en la gráfica inicial de la serie.

Se observa también en el primer gráfico que el tercer mes del año tiene muetsras con valores que aumentan considerablemente en marzo y seguidamente caen ligeramente en el abril o viceversa. Posiblemente este fenómeno esté relacionado con los efectos de calendario, ya que por esos meses se encuentra la festividad de Semana Santa, la cual se distribuye entre ambos meses de manera distinta dependiendo el año. Con lo cual, genera estos aumentos que se detectan en marzo cuando la Semana Santa ocurre en mayor parte en Abril y por otro lado, los aumentos del mes de abril corresponden a los años para los que la Semana Santa tuvo lugar más en el mes de marzo. Más adelante se discutirá el tratamiento de dicho efecto.

Se ha confirmado la presencia de un patrón estacional, por lo que se procede a realizar la diferenciación estacional de orden 12. Esto impica que el valor del parámetro $D$ toma el valor de la unidad.

$$(1-B^{12})X_t$$

```{r}
d12bcser = diff(bcser,12)
plot_ly() %>%
  add_trace(x=~time(d12bcser), y=~d12bcser,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d12bcser), y=~mean(d12bcser),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Time Series after seasonal differentation <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
```

```{r}
monthplot(d12bcser)
```

Tras la transformación se puede observar en el gráfico de arriba que las subseries de los meses presentan una misma media, constante horizontalmente. De la misma forma, ya no es visible una dependencia entre muestras del mismo periodo, con lo que se ha eliminado el patrón estacional.

```{r}
ts_seasonal(d12bcser, type="all", title=" <b> Seasonality plot for Time Series <b>")
```

Para corroborar que la transformación sean apropiadas basta con observar la descomposición estacional tras dicha transformación para ver que se ha eliminado todo rastro de un patrón.

#### Media constante

Tras la eliminación del patrón estacional observamos que la serie no presenta signos de una tendencia lineal o algún tipo de tendencia, por lo que podemos considerar ya de entrada la media como constante. Aunque para comprobar se compararán la variancia de la serie con solo la diferenciación estacional y su variancia tras aplicarle una diferenciación regular a esta última.

```{r}
var(d12bcser)
var(diff(d12bcser))
var(diff(diff(d12bcser)))
```

Como la variancia de la serie aumenta tras la segunda diferenciación regular, se identifica que se ha realizado una sobrediferenciación. Esto implica que no es necesaria la aplicación de la segunda trasnformación para asegurar media constante, solo basta con la primera. Obteniendo el parámetro $d=1$.

```{r}
d1d12bcser = diff(d12bcser)
```

### Serie estacionaria

Tras el proceso de transformaciones, únicamente se ha requerido una diferenciación estacional y una diferenciación regular para la serie original. Con lo que la serie estacionaria $W_t$ resulta ser:

$$W_t = (1-B)(1-B^{12})\frac{X_t^\lambda-1}{\lambda} \ \ , \ \lambda≃0.395$$

```{r}
plot_ly() %>%
  add_trace(x=~time(d1d12bcser), y=~d1d12bcser,
            type = "scatter",
            fill="tonexty",
            mode="lines",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            name='Time Series'
            ) %>%
  add_trace(x=~time(d12bcser), y=~mean(d12bcser),
            type = "scatter",
            mode="lines",
            name='Mean',
            line=list(color='#rgb(68, 1, 84)', dash='dash')
            ) %>%
  layout(title='<b> Stationary Time Series <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)')) 
```

### Modelos propuestos

Para poder proponer modelos deben analizarse los gráficos del ACF y el PACF de la serie tras haberle aplicado las transformaciones.

```{r}
ts_cor(d1d12bcser, lag.max = 72)
```

Si bien es cierto que se observar cierta tendencia logarítmica en los retrasos del PACF, se considera que es el más adecuado para considerar los retrasos finitos inicialmente. Siendo el gráfico del ACF el que contiene infinitos retrasos no nulos.

Para determinar los valores de `p, P` y `q, Q` se necesita contar el número de retrasos hasta la última barra significativamente diferente de 0. $\rho(h) \neq 0$. Con lo que la última barra debe encontrarse fuera de las bandas del intervalo de confianza para poder rechazar la hipótesis nula de significación de $\rho(h)$.

$$H_0: \rho(h) = 0 \\ H_1: \rho(h) \neq 0$$

Comenzando por la parte estacional, se podría considerar ajustar AR(1), AR(2) y AR(4). Pues esta claro que el primer retraso estacional es significativo, mientras que el segundo y el cuarto sobresalen ligeramente por el límite inferior del intervalo de confianza. La opción de escoger una parte autoregresiva con $p=1$ puede razonarse como correcta al aportar una baja complejidad al modelo, sin embargo no es un candidato deseable al poder estar dejando parte sin explicar.Con lo que es favorable decantarse por un AR(4) ya que se tendría en cuenta un mayor número de relaciones entre las variables del pasado, y si resulta haber parámetros no significativos, estos se pueden eliminar del ajuste.

Aun sabiendo que los retrasos del ACF no presentan un decreciemiento evidente, se podría considerar una media móvil de parámetro $q=6$, pues aunque los retrasos intermedios no presentan significación clara, el sexto retraso esatcional si es significativo. En cambio esta propuesta incorpora al modelo una mayor complejidad en comparación con la parte autoregresiva propuesta con antelación, con lo que nos decantaremos por mantener solamente una parte AR(4) o bien proponer un ARMA que explique esta parte estacional.

EXPLICAR ARMA ESTACIONAL

Para la parte regular resulta muy evdiente que la mejor opción es un AR(2), debido a que son los únicos dos retrasos con obvia significación. El resto de barras muestran este decreciemiento ya mencionado y aunque algunas sobresalen, estan suficientemente lejos del origen como para considerarse como fruto del $5%$ de azar en las observaciones.

No obstante, considerando únicamente un número limitado de los primeros retrasos del ACF, una propuesta MA(4) sería suficiente, pese a que se obviarían los retrasos siguientes. Por lo que se tendría que suponer que los retrasos significativos lejos del origen son causados como satélites de los retrasos estacionales.

Por el número de parámetros entre $p$ y $q$, se evaluará proponer un modelo ARMA para reducir la complejidad del modelo, mientras que se busca una explicación conjunta para el modelo.

EXPLICAR ARMA

ARMA(1,1) ARMA(1,2) ARMA(2,1)

EXPLICAR LOS 4 MODELOS ESCOGIDOS

```{r}
arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(0,0,6), period=12))
cat("---------------------------------------------------------------------")
arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(4,0,0), period=12))
cat("---------------------------------------------------------------------")
arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(2,0,2), period=12))
cat("---------------------------------------------------------------------")
arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(2,0,1), period=12))

```

JUSTFICAR LA SELECCION DE LOS DOS MEJORES

### Estimación modelo 1

El modelo 1 $\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$ de la forma:

$$(1 - \phi_1 B - \phi_2 B^2)(1 - \Phi_1 B^{12} - \Phi_2 B^{24} - \Phi_3 B^{36} - \Phi_4 B^{48})(1-B)(1-B^{12})\frac{(X_t - \mu_1)^\lambda-1}{\lambda} = (1+ \theta_1 B)Z_t$$

Para la estimación del modelo 1 se ha de comprobar primeramente si la media de la serie es significativa o no.

Se comprueba la significación de $\hat{\mu_1}$ mediante su $t$-ratio para determinar si es significante para el modelo, es decir, si se acepta la hipótesis nula de que la media es igual a 0.

$$H_0: \hat{\mu_1} = 0 \\ H_1: \hat{\mu_1} \neq 0$$ 

donde el $t$-ratio viene dado por

$$t = \frac{\hat{\mu_1}}{S_{W_t}} \sim N(0,1)$$

asintoticamente normal al tratarse de un estimador calculado a partir del estimador de máxima verosimilitud.

```{r}
m1 = arima(d1d12bcser, order=c(2,0,1), seasonal=list(order=c(4,0,0), period=12))
m1
```

```{r}
cat("Is the mean significant?",abs(m1$coef[8]/sqrt(diag(m1$var.coef)[8])) > 2)
```

Al no tener significación la media de la serie $\hat{\mu_1}$, se puede aplicar la función `arima` a la serie después de la transformación *Box-Cox*, aplicandole las diferenciaciones como parámetros a la función, de esta manera se evitan deshacer las transformaciones después y se puede predecir directamente sobre la serie transformada.

```{r}
m1 = arima(bcser, order=c(2,1,1), seasonal=list(order=c(4,1,0), period=12))
m1
```

Verificamos que la decisión de retirar la media del modelo ha sido la adecuada en terminos del AIC del nuevo ajuste. Además como $\hat{\mu_1}$ no es significativa, se ve que los valores de los estimadores del modelo no han variado en gran escala, al igual que sus desviaciones estandar.

Bajo la misma hipótesis, se comprobará la significación de los estimadores del modelo.

```{r}
cat("\nT-ratios:",round(m1$coef/sqrt(diag(m1$var.coef)),2))
```

Se observa que el estimador del parámetro $\hat{\theta_1}$ está por debajo del borde del intervalo de confianza, por lo que ajustaremos un modelo eliminandolo y se compararán ambos modelos en terminos de su AIC.

```{r}
arima(bcser, order=c(2,1,1), seasonal=list(order=c(4,1,0), period=12),
           fixed=c(NA,NA,0,NA,NA,NA,NA))
```

En vista de que el AIC ha aumentado tras eliminar $\hat{\theta_1}$, se considerará que el modelo incial es más adecuado.

El resto de parámetros si son significativos, como se ha visto anteriormente, con lo que el modelo estimado $\mbox{ARIMA}(2,1,1)(4,1,0)_{12}$ es:

$$(1 + 0.7602 B + 0.3825 B^2)(1 + 0.5954 B^{12} + 0.6411 B^{24} + 0.4560 B^{36} + 0.4251 B^{48})(1-B)(1-B^{12})\frac{(X_t - \mu_1)^\lambda-1}{\lambda} = (1 + 0.2315 B)Z_t$$



### Estimación modelo 2

El modelo 2 $\mbox{ARIMA}(2,1,0)(2,1,2)_{12}$ de la forma:

$$(1 - \phi_1 B - \phi_2 B^2)(1 - \Phi_1 B^{12} - \Phi_2 B^{24})(1-B)(1-B^{12})\frac{(X_t - \mu_2)^\lambda-1}{\lambda} = (1+ \Theta_1 B^{12} + \Theta_2 B^{24})Z_t$$

```{r}
m2 = arima(d1d12bcser, order=c(2,0,0), seasonal=list(order=c(2,0,2), period=12))
m2
```

```{r}
cat("Is the mean significant?",abs(m2$coef[7]/sqrt(diag(m2$var.coef)[7])) > 2)
```

```{r}
m2 = arima(bcser, order=c(2,1,0), seasonal=list(order=c(2,1,2), period=12))
m2
```

```{r}
cat("\nT-ratios:",round(m2$coef/sqrt(diag(m2$var.coef)),2))
```


## Validación

... (10 de 4)


### Variancia constante de residuos

A modo de validar la condición de homocedasticidad de la variancia en los residuos, nos apoyaremos en el gráfico de residuos para diagnosticar la bondad de ajuste del modelo 1. Con la intención de detectar si el modelo captura completamente la estructura de la serie temporal.


#### Modelo 1

Observamos que los residuos del modelo 1 presentan dos valores por debajo del límite inferior de las bandas de probabilidad, lo cual respecta a $0.833%$ de los valores. A pesar de que no es un porcentaje elevado respecto a lo que consideramos indicativo de un problema, estos posibles valores atípicos del modelo serán comentados a profundidad en el apartado de tratamiento de atípicos.

En términos de la variancia, vemos una dispersión de los residuos alrededor del 0 sin ningún patrón claro, lo que sugiere que el modelo genera una aproximación a las observaciones aceptable.

```{r}
resi1 <- resid(m1)

plot_ly() %>%
  add_trace(x=~time(bcser), y=~resi1,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 1'
            ) %>%
  add_lines(x=~time(bcser), y=~-3*sd(resi1),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(bcser), y=~3*sd(resi1),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 1 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

```

En cuanto a la volatilidad de la serie se puede mencionar que no hay evidencias visuales de fluctuación de la variailidad en periodos de tiempo determinados.

No obstante, la variancia de los residuos no se puede declarar constante, dado que en el desenlace de las muestras se observa una variancia creciente en comparación con el inicio de la misma. Comprobamos este hecho mediante un ajuste local suave de le la variabilidad, en donde la linea de ajuste muestra una curvatura a lo largo de los residuos, además de tener intervalos de confianza de mayor amplitud hacia el final de las observaciones.

```{r}
# scatter.smooth(sqrt(abs(resi1)), lpars=list(col=2))

ggfig = ggplot(data=NULL, aes(x=time(bcser), y=abs(resi1))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 1)") +
  ggtitle(" <b> Absolute value of model 1 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(ggfig)
```

CONCLUSION

#### Modelo 2

```{r}
resi2 <- resid(m2)

plot_ly() %>%
  add_trace(x=~time(bcser), y=~resi2,
            type = "scatter",
            fill="tonexty",
            line = list(color = "#2a788e"),
            fillcolor="rgba(42, 120, 142, 0.5)",
            mode="lines",
            name='Residuals of model 2'
            ) %>%
  add_lines(x=~time(bcser), y=~-3*sd(resi2),
            fill=F,
            line=list(color='#440154',dash='dot'),
            name='Lower IC limit'
            ) %>%
  add_lines(x=~time(bcser), y=~3*sd(resi2),
            fill=F,
            line=list(color='#440154', dash='dot'),
            name="Upper IC limit"
            ) %>%
  layout(title='<b> Residuals of model 2 <b>',
         xaxis=list(title='Time'),
         yaxis=list(title='(Thousand million euros)'))

```

```{r}
ggfig = ggplot(data=NULL, aes(x=time(bcser), y=abs(resi2))) +
  geom_smooth(fill="#2a788e") + 
  geom_point(color="#440154", fill='#414487', shape=21) +
  theme_bw() + 
  xlab("Time") + ylab("abs(residuals 2)") +
  ggtitle(" <b> Absolute value of model 2 residuals <b>") +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(ggfig)
```

### Hipótesis de normalidad de residuos

#### Modelo 1

...

```{r}
ggplot(data=NULL, aes(sample=resi1)) +
  stat_qq_band(color='#1F968BFF', fill='#1F968BFF') +
  stat_qq_line(color='#39568CFF') +
  stat_qq_point(color="#440154FF", fill='#440154FF', shape=21) +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle("Normal Q-Q Plot") +
  theme(plot.title = element_text(hjust = 0.5))

ggfig = ggplot(data=NULL, aes(sample=resi1)) +
  geom_qq(color="darkblue", fill='blue', shape=21) +
  geom_qq_line(color='purple') +
  theme_bw() +
  xlab("Theoretical Quantiles") + ylab("Sample Quantiles") +
  ggtitle(" <b> Normal Q-Q Plot <b>") +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(ggfig)
```

```{r}
hist(resi1,breaks=20, freq=FALSE)
d <- curve(dnorm(x, mean=mean(resi1), sd=sd(resi1)), col=2, add=T)

plot_ly() %>%
  add_histogram(x=~resi1,
        name="Model 1 residuals",
        marker = list(color = "#22a884",
                      line = list(color = "#2a788e", width = 2))
        ) %>%
  add_trace(x=~d$x, y=~d$y,
            type = 'scatter',
            mode = 'none',
            name = "Density curve",
            fill = "tozeroy",
            fillcolor="rgba(168, 216, 234, 0.5)",
            yaxis = "y2"
            ) %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right", title = "",
                       zeroline = FALSE,
                       showline = FALSE,
                       showticklabels = FALSE,
                       showgrid = FALSE),
         title='<b> Histogram of model 1 residuals <b>',
         xaxis=list(title='Residuals'),
         yaxis=list(title='Density')
         )
```

```{r}
shapiro.test(resi1)
```

#### Modelo 2

### Independencia de residuos

#### Modelo 1

...

```{r}
ts_cor(resi1, lag.max = 72)
```

```{r}
tsdiag(m1,gof.lag=72)
```

#### Modelo 2

### Propiedad de causalidad y/o estacionalidad

A fin de comprobar la causalidad de un modelo se ha de comprobar que los pesos $\psi_i$ de

$$\phi(B) = \frac{\theta_q(B)}{\phi_p(B)}$$

convergan, de modo que se pueda expresar como un $\mbox{MA}(\infty)$. Lo cuál será de gran utilidad a la hora del cálculo de la variancia de las predicciones puntuales realizadas en breve.

Para asegurar la invertibilidad de un modelo, se ha de comprobar, de manera análoga, que los pesos $\pi_i$ de

$$\pi(B) = \frac{\phi_p(B)}{\theta_q(B)}$$
tengan convergencia, de modo que se obtenga una expresión $\mbox{AR}(\infty)$. Bajo esta propiedad y con el uso de observaciones pasadas será posible el cálculo de las predicciones puntuales en el apartado de predicciones.


#### Modelo 1

Al ver que todas las raices del polinomio de grado $50$ son mayores que la unidad, podemos confirmar que el modelo 1 es causal.

```{r}
Mod(polyroot(c(1,-m1$model$phi)))
```
Como solo hay una raíz para la componente de media móvil del modelo y tiene módulo mayor que 1, el modelo 1 también cumple con la caondición de invertible.

```{r}
Mod(polyroot(c(1,m1$model$theta)))
```


```{r}
ggfig <- autoplot(m1) +
  geom_point(color="#440154", fill='#414487', shape=21, size=1) +
  theme_bw() +
  ggtitle(" <b> Invers roots model 1 <b>") +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(ggfig)
```

Se comprueba visualmente que, en este caso, la inversa de las raices de los dos polinomios caen dentro del circulo unitario, por lo tanto, el modelo 1 es tanto causal como invertible.

#### Modelo 2

```{r}
Mod(polyroot(c(1,-m2$model$phi)))
```

```{r}
Mod(polyroot(c(1,m2$model$theta)))
```

```{r}
ggfig <- autoplot(m2) +
  geom_point(color="#440154", fill='#414487', shape=21, size=1) +
  theme_bw() +
  ggtitle(" <b> Invers roots model 1 <b>") +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(ggfig)
```

### Estabilidad

#### Modelo 1

...

#### Modelo 2

## Previsiones

#### Modelo 1

...

#### Modelo 2

## Tratamiento de atípicos

#### Modelo 1

...

#### Modelo 2

# Conclusiones y discusión

...

# Bibliografía

...

.
